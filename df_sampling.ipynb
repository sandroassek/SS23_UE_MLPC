{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os, glob\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0: other',\n",
       " '1: comcuc',\n",
       " '2: cowpig1',\n",
       " '3: eucdov',\n",
       " '4: eueowl1',\n",
       " '5: grswoo',\n",
       " '6: tawowl1']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('trainset_python/python/class_names.txt') as f:\n",
    "    classes = f.readlines()\n",
    "\n",
    "for i,c in enumerate(classes):\n",
    "    classes[i] = c.strip()\n",
    "    \n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "548"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('trainset_python/python/feature_names.txt') as f:\n",
    "    features = f.readlines()\n",
    "\n",
    "for i,feature in enumerate(features):\n",
    "    features[i] = feature.strip()\n",
    "    \n",
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all files in one dataframe\n",
    "idx = pd.Series([i for i in range(100)])\n",
    "\n",
    "rootdir = os. getcwd()\n",
    "files = pd.DataFrame([])\n",
    "files_stand = pd.DataFrame([])\n",
    "lables = pd.DataFrame([])\n",
    "data = pd.DataFrame([])\n",
    "data_stand = pd.DataFrame([])\n",
    "    \n",
    "for i,f in enumerate(glob.glob(rootdir + '/**/*.npy', recursive=True)):\n",
    "    if (i % 2) == 0:\n",
    "        lable = pd.DataFrame(np.load(f))\n",
    "        #lable = lable.rename(columns={lable.columns[0]: \"overall_class\"})\n",
    "        for i, col in enumerate(lable.columns):\n",
    "            if i == 0:\n",
    "                lable = lable.rename(columns={lable.columns[0]: \"overall_class_vote\"})\n",
    "            else:\n",
    "                lable = lable.rename(columns={col: \"class_vote_\" + str(i)})\n",
    "        if lables.empty:\n",
    "            lables = lable\n",
    "        else:\n",
    "            idx = idx + (i*100)\n",
    "            lable.index = idx\n",
    "            lables = lables.append(lable)\n",
    "    else:\n",
    "        file = pd.DataFrame(np.load(f), columns = features)\n",
    "        file_stand = pd.DataFrame(StandardScaler().fit_transform(np.load(f)), columns = features)\n",
    "        if files.empty:\n",
    "            files = file\n",
    "        else:\n",
    "            idx = idx + (i*100)\n",
    "            file.index = idx\n",
    "            files = files.append(file)\n",
    "        if files_stand.empty:\n",
    "            files_stand = file_stand\n",
    "        else:\n",
    "            idx = idx + (i*100)\n",
    "            file_stand.index = idx\n",
    "            files_stand = files_stand.append(file_stand)\n",
    "\n",
    "\n",
    "lables.index = pd.Series([i for i in range(len(lables))])\n",
    "files.index = pd.Series([i for i in range(len(lables))])\n",
    "files_stand.index = pd.Series([i for i in range(len(lables))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "overall_class_vote    5.0\n",
       "class_vote_1          5.0\n",
       "class_vote_2          5.0\n",
       "class_vote_3          5.0\n",
       "class_vote_4          NaN\n",
       "class_vote_5          NaN\n",
       "class_vote_6          NaN\n",
       "class_vote_7          NaN\n",
       "Name: 81101, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lables.loc[81101]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_stand_incl_labels = pd.concat([files_stand, lables], axis=1, join='inner')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class_vote_1    0.0\n",
       "class_vote_2    0.0\n",
       "class_vote_3    0.0\n",
       "class_vote_4    1.0\n",
       "class_vote_5    0.0\n",
       "class_vote_6    0.0\n",
       "class_vote_7    NaN\n",
       "Name: 0, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_stand_incl_labels.loc[0, ['class_vote_1', 'class_vote_2', 'class_vote_3',\n",
    "                              'class_vote_4', 'class_vote_5', 'class_vote_6', 'class_vote_7']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "def sample_dataframe_by_threshold(hyper_param_threshold_idx):\n",
    "    thresholds = np.array([1/7, 2/7, 3/7, 4/7, 5/7, 6/7, 7/7])\n",
    "    dropped_indices = []\n",
    "    nr_annotators = [0, 0, 0, 0, 0]\n",
    "\n",
    "    print(f'Total samples: {len(file_stand_incl_labels)}')\n",
    "    for n, threshold in enumerate(thresholds):\n",
    "        invalid_samples = 0\n",
    "        inner_list_dropped_indices = []\n",
    "        for i, sample in enumerate(file_stand_incl_labels.copy().to_numpy()[:, -7:]):\n",
    "            sample_has_nans = 0\n",
    "            sample_nan_idx = []\n",
    "            for l, val in enumerate(sample):\n",
    "                if math.isnan(val):\n",
    "                    sample_nan_idx.append(l)\n",
    "                    sample_has_nans += 1\n",
    "            # remove nans from sample\n",
    "            sample = np.delete(sample, sample_nan_idx)\n",
    "            # print(sample)\n",
    "            classes_vote = [np.count_nonzero((sample == 1) | (sample == 1.0)), np.count_nonzero((sample == 2) | (sample == 2.0)), np.count_nonzero((sample == 3) | (sample == 3.0)),\n",
    "                            np.count_nonzero((sample == 4) | (sample == 4.0)), np.count_nonzero((sample == 5) | (sample == 5.0)), np.count_nonzero((sample == 6) | (sample == 6.0))]\n",
    "            # accept fragments with no votes and votes above current threshold\n",
    "            if np.max(classes_vote) / len(sample) > 0:\n",
    "                \"\"\"if len(sample) == 3 and np.max(classes_vote) / len(sample) < 3/3:\n",
    "                    invalid_samples += 1\n",
    "                    inner_list_dropped_indices.append(i)\n",
    "                    nr_annotators[0] += 1\"\"\"\n",
    "                if len(sample) == 4 and np.max(classes_vote) / len(sample) < 3/4:\n",
    "                    invalid_samples += 1\n",
    "                    inner_list_dropped_indices.append(i)\n",
    "                    nr_annotators[1] += 1\n",
    "                elif len(sample) == 5 and np.max(classes_vote) / len(sample) < 3/5:\n",
    "                    invalid_samples += 1\n",
    "                    inner_list_dropped_indices.append(i)\n",
    "                    nr_annotators[2] += 1\n",
    "                elif len(sample) == 6 and np.max(classes_vote) / len(sample) < 4/6:\n",
    "                    invalid_samples += 1\n",
    "                    inner_list_dropped_indices.append(i)\n",
    "                    nr_annotators[3] += 1\n",
    "                elif len(sample) == 7 and np.max(classes_vote) / len(sample) < 5/7:\n",
    "                    invalid_samples += 1\n",
    "                    inner_list_dropped_indices.append(i)\n",
    "                    nr_annotators[4] += 1\n",
    "                    \n",
    "        dropped_indices.append(inner_list_dropped_indices)\n",
    "        print(\n",
    "            f'Samples where annotators agree >= {threshold*100}%: {len(file_stand_incl_labels) - invalid_samples} (dropped samples: {invalid_samples})')\n",
    "    \n",
    "    # drop the samples with < threshold than selected    \n",
    "    sampled_dataframe = file_stand_incl_labels.drop(dropped_indices[hyper_param_threshold_idx]).reset_index()\n",
    "    # drop vote columns and index_column\n",
    "    sampled_dataframe = sampled_dataframe.iloc[:, 1:-8]\n",
    "    print(nr_annotators)\n",
    "    return sampled_dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 120000\n",
      "Samples where annotators agree >= 14.285714285714285%: 111007 (dropped samples: 8993)\n",
      "Samples where annotators agree >= 28.57142857142857%: 106373 (dropped samples: 13627)\n",
      "Samples where annotators agree >= 42.857142857142854%: 103834 (dropped samples: 16166)\n",
      "Samples where annotators agree >= 57.14285714285714%: 101648 (dropped samples: 18352)\n",
      "Samples where annotators agree >= 71.42857142857143%: 99532 (dropped samples: 20468)\n",
      "Samples where annotators agree >= 85.71428571428571%: 96779 (dropped samples: 23221)\n",
      "Samples where annotators agree >= 100.0%: 92805 (dropped samples: 27195)\n",
      "[1512, 0, 10899, 50540, 65071]\n"
     ]
    }
   ],
   "source": [
    "sampled_dataframe = sample_dataframe_by_threshold(hyper_param_threshold_idx=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zcr_mean</th>\n",
       "      <th>zcr_std</th>\n",
       "      <th>yin_0</th>\n",
       "      <th>yin_1</th>\n",
       "      <th>yin_2</th>\n",
       "      <th>yin_3</th>\n",
       "      <th>yin_4</th>\n",
       "      <th>yin_5</th>\n",
       "      <th>yin_6</th>\n",
       "      <th>yin_7</th>\n",
       "      <th>...</th>\n",
       "      <th>cln_contrast_mean_4</th>\n",
       "      <th>cln_contrast_mean_5</th>\n",
       "      <th>cln_contrast_mean_6</th>\n",
       "      <th>cln_contrast_std_0</th>\n",
       "      <th>cln_contrast_std_1</th>\n",
       "      <th>cln_contrast_std_2</th>\n",
       "      <th>cln_contrast_std_3</th>\n",
       "      <th>cln_contrast_std_4</th>\n",
       "      <th>cln_contrast_std_5</th>\n",
       "      <th>cln_contrast_std_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.167208</td>\n",
       "      <td>-0.526000</td>\n",
       "      <td>-0.605283</td>\n",
       "      <td>-0.644997</td>\n",
       "      <td>-0.667503</td>\n",
       "      <td>-0.714700</td>\n",
       "      <td>-0.783143</td>\n",
       "      <td>-0.637137</td>\n",
       "      <td>-0.684710</td>\n",
       "      <td>-0.702930</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.427318</td>\n",
       "      <td>0.074920</td>\n",
       "      <td>-0.115683</td>\n",
       "      <td>0.804020</td>\n",
       "      <td>1.606063</td>\n",
       "      <td>-1.114032</td>\n",
       "      <td>-0.851041</td>\n",
       "      <td>-0.778650</td>\n",
       "      <td>-0.453525</td>\n",
       "      <td>0.479612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.461319</td>\n",
       "      <td>-0.636900</td>\n",
       "      <td>-0.578792</td>\n",
       "      <td>-0.649733</td>\n",
       "      <td>-0.671045</td>\n",
       "      <td>-0.717349</td>\n",
       "      <td>-0.780945</td>\n",
       "      <td>-0.636216</td>\n",
       "      <td>-0.683018</td>\n",
       "      <td>-0.700525</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.224404</td>\n",
       "      <td>-0.914364</td>\n",
       "      <td>-0.323859</td>\n",
       "      <td>-1.849531</td>\n",
       "      <td>1.352744</td>\n",
       "      <td>-0.486672</td>\n",
       "      <td>-1.106791</td>\n",
       "      <td>-0.014905</td>\n",
       "      <td>-0.742246</td>\n",
       "      <td>0.318966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.854948</td>\n",
       "      <td>-0.895040</td>\n",
       "      <td>-0.577355</td>\n",
       "      <td>-0.647228</td>\n",
       "      <td>1.701700</td>\n",
       "      <td>1.539210</td>\n",
       "      <td>1.367054</td>\n",
       "      <td>1.740341</td>\n",
       "      <td>1.636040</td>\n",
       "      <td>1.694016</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.778076</td>\n",
       "      <td>-0.928394</td>\n",
       "      <td>-0.319547</td>\n",
       "      <td>-0.412680</td>\n",
       "      <td>0.388380</td>\n",
       "      <td>0.980363</td>\n",
       "      <td>-0.796871</td>\n",
       "      <td>-0.166418</td>\n",
       "      <td>-1.076733</td>\n",
       "      <td>-0.265297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.822960</td>\n",
       "      <td>-0.542231</td>\n",
       "      <td>-0.608296</td>\n",
       "      <td>1.754146</td>\n",
       "      <td>1.784766</td>\n",
       "      <td>1.610830</td>\n",
       "      <td>1.431633</td>\n",
       "      <td>1.783958</td>\n",
       "      <td>1.649853</td>\n",
       "      <td>1.716896</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.623868</td>\n",
       "      <td>-1.209971</td>\n",
       "      <td>-0.311791</td>\n",
       "      <td>-0.557688</td>\n",
       "      <td>-0.121353</td>\n",
       "      <td>1.415610</td>\n",
       "      <td>-0.072873</td>\n",
       "      <td>-0.584790</td>\n",
       "      <td>-0.472864</td>\n",
       "      <td>-0.260567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.185489</td>\n",
       "      <td>-0.650381</td>\n",
       "      <td>1.920336</td>\n",
       "      <td>1.733858</td>\n",
       "      <td>1.769065</td>\n",
       "      <td>1.630653</td>\n",
       "      <td>1.431748</td>\n",
       "      <td>1.716913</td>\n",
       "      <td>1.575559</td>\n",
       "      <td>1.648439</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.204925</td>\n",
       "      <td>-1.441965</td>\n",
       "      <td>0.677037</td>\n",
       "      <td>-0.175322</td>\n",
       "      <td>-0.255244</td>\n",
       "      <td>0.513171</td>\n",
       "      <td>-1.169459</td>\n",
       "      <td>-0.658233</td>\n",
       "      <td>-0.090633</td>\n",
       "      <td>0.319449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99527</th>\n",
       "      <td>-0.331513</td>\n",
       "      <td>0.356134</td>\n",
       "      <td>-0.844403</td>\n",
       "      <td>-0.858645</td>\n",
       "      <td>-0.641962</td>\n",
       "      <td>-0.805758</td>\n",
       "      <td>-0.697388</td>\n",
       "      <td>-0.642756</td>\n",
       "      <td>-0.856450</td>\n",
       "      <td>-0.796840</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.286449</td>\n",
       "      <td>-0.457386</td>\n",
       "      <td>-0.313910</td>\n",
       "      <td>1.092455</td>\n",
       "      <td>-1.203601</td>\n",
       "      <td>0.934860</td>\n",
       "      <td>-0.202530</td>\n",
       "      <td>-0.613064</td>\n",
       "      <td>0.010541</td>\n",
       "      <td>0.138739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99528</th>\n",
       "      <td>-1.220233</td>\n",
       "      <td>-0.828050</td>\n",
       "      <td>-0.903588</td>\n",
       "      <td>-0.687250</td>\n",
       "      <td>-0.680983</td>\n",
       "      <td>-0.653949</td>\n",
       "      <td>-0.680398</td>\n",
       "      <td>-0.549913</td>\n",
       "      <td>-0.753115</td>\n",
       "      <td>-0.687278</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024849</td>\n",
       "      <td>-0.176945</td>\n",
       "      <td>-0.326877</td>\n",
       "      <td>0.339264</td>\n",
       "      <td>0.115136</td>\n",
       "      <td>-0.538031</td>\n",
       "      <td>1.039460</td>\n",
       "      <td>0.106102</td>\n",
       "      <td>-0.789529</td>\n",
       "      <td>0.160393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99529</th>\n",
       "      <td>-0.438986</td>\n",
       "      <td>-0.523291</td>\n",
       "      <td>-0.908066</td>\n",
       "      <td>-0.808672</td>\n",
       "      <td>-0.801250</td>\n",
       "      <td>-0.614802</td>\n",
       "      <td>-0.844231</td>\n",
       "      <td>-0.732196</td>\n",
       "      <td>-0.812538</td>\n",
       "      <td>-0.531270</td>\n",
       "      <td>...</td>\n",
       "      <td>0.102378</td>\n",
       "      <td>-0.428485</td>\n",
       "      <td>-0.163334</td>\n",
       "      <td>-0.339807</td>\n",
       "      <td>1.281501</td>\n",
       "      <td>1.089032</td>\n",
       "      <td>0.429298</td>\n",
       "      <td>0.445736</td>\n",
       "      <td>-0.984278</td>\n",
       "      <td>-0.468615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99530</th>\n",
       "      <td>-0.856478</td>\n",
       "      <td>-0.580928</td>\n",
       "      <td>-0.195463</td>\n",
       "      <td>-0.084748</td>\n",
       "      <td>-0.035737</td>\n",
       "      <td>-0.576595</td>\n",
       "      <td>-0.475360</td>\n",
       "      <td>-0.519312</td>\n",
       "      <td>-0.610353</td>\n",
       "      <td>-0.561646</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.584563</td>\n",
       "      <td>-0.117808</td>\n",
       "      <td>-0.142838</td>\n",
       "      <td>-0.283224</td>\n",
       "      <td>-0.190104</td>\n",
       "      <td>-0.195900</td>\n",
       "      <td>0.225551</td>\n",
       "      <td>-1.174491</td>\n",
       "      <td>-0.516408</td>\n",
       "      <td>0.472931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99531</th>\n",
       "      <td>-1.877472</td>\n",
       "      <td>0.710855</td>\n",
       "      <td>0.072642</td>\n",
       "      <td>-0.633977</td>\n",
       "      <td>-0.598054</td>\n",
       "      <td>-0.447791</td>\n",
       "      <td>-0.506353</td>\n",
       "      <td>-0.593066</td>\n",
       "      <td>-0.659019</td>\n",
       "      <td>-0.600411</td>\n",
       "      <td>...</td>\n",
       "      <td>0.150058</td>\n",
       "      <td>-0.102807</td>\n",
       "      <td>-0.238260</td>\n",
       "      <td>-1.239245</td>\n",
       "      <td>-0.300357</td>\n",
       "      <td>2.887519</td>\n",
       "      <td>-0.368612</td>\n",
       "      <td>0.053349</td>\n",
       "      <td>-0.292865</td>\n",
       "      <td>0.016332</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99532 rows × 548 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       zcr_mean   zcr_std     yin_0     yin_1     yin_2     yin_3     yin_4  \\\n",
       "0      0.167208 -0.526000 -0.605283 -0.644997 -0.667503 -0.714700 -0.783143   \n",
       "1      0.461319 -0.636900 -0.578792 -0.649733 -0.671045 -0.717349 -0.780945   \n",
       "2      0.854948 -0.895040 -0.577355 -0.647228  1.701700  1.539210  1.367054   \n",
       "3      0.822960 -0.542231 -0.608296  1.754146  1.784766  1.610830  1.431633   \n",
       "4      1.185489 -0.650381  1.920336  1.733858  1.769065  1.630653  1.431748   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "99527 -0.331513  0.356134 -0.844403 -0.858645 -0.641962 -0.805758 -0.697388   \n",
       "99528 -1.220233 -0.828050 -0.903588 -0.687250 -0.680983 -0.653949 -0.680398   \n",
       "99529 -0.438986 -0.523291 -0.908066 -0.808672 -0.801250 -0.614802 -0.844231   \n",
       "99530 -0.856478 -0.580928 -0.195463 -0.084748 -0.035737 -0.576595 -0.475360   \n",
       "99531 -1.877472  0.710855  0.072642 -0.633977 -0.598054 -0.447791 -0.506353   \n",
       "\n",
       "          yin_5     yin_6     yin_7  ...  cln_contrast_mean_4  \\\n",
       "0     -0.637137 -0.684710 -0.702930  ...            -1.427318   \n",
       "1     -0.636216 -0.683018 -0.700525  ...            -0.224404   \n",
       "2      1.740341  1.636040  1.694016  ...            -0.778076   \n",
       "3      1.783958  1.649853  1.716896  ...            -1.623868   \n",
       "4      1.716913  1.575559  1.648439  ...            -0.204925   \n",
       "...         ...       ...       ...  ...                  ...   \n",
       "99527 -0.642756 -0.856450 -0.796840  ...            -0.286449   \n",
       "99528 -0.549913 -0.753115 -0.687278  ...             0.024849   \n",
       "99529 -0.732196 -0.812538 -0.531270  ...             0.102378   \n",
       "99530 -0.519312 -0.610353 -0.561646  ...            -0.584563   \n",
       "99531 -0.593066 -0.659019 -0.600411  ...             0.150058   \n",
       "\n",
       "       cln_contrast_mean_5  cln_contrast_mean_6  cln_contrast_std_0  \\\n",
       "0                 0.074920            -0.115683            0.804020   \n",
       "1                -0.914364            -0.323859           -1.849531   \n",
       "2                -0.928394            -0.319547           -0.412680   \n",
       "3                -1.209971            -0.311791           -0.557688   \n",
       "4                -1.441965             0.677037           -0.175322   \n",
       "...                    ...                  ...                 ...   \n",
       "99527            -0.457386            -0.313910            1.092455   \n",
       "99528            -0.176945            -0.326877            0.339264   \n",
       "99529            -0.428485            -0.163334           -0.339807   \n",
       "99530            -0.117808            -0.142838           -0.283224   \n",
       "99531            -0.102807            -0.238260           -1.239245   \n",
       "\n",
       "       cln_contrast_std_1  cln_contrast_std_2  cln_contrast_std_3  \\\n",
       "0                1.606063           -1.114032           -0.851041   \n",
       "1                1.352744           -0.486672           -1.106791   \n",
       "2                0.388380            0.980363           -0.796871   \n",
       "3               -0.121353            1.415610           -0.072873   \n",
       "4               -0.255244            0.513171           -1.169459   \n",
       "...                   ...                 ...                 ...   \n",
       "99527           -1.203601            0.934860           -0.202530   \n",
       "99528            0.115136           -0.538031            1.039460   \n",
       "99529            1.281501            1.089032            0.429298   \n",
       "99530           -0.190104           -0.195900            0.225551   \n",
       "99531           -0.300357            2.887519           -0.368612   \n",
       "\n",
       "       cln_contrast_std_4  cln_contrast_std_5  cln_contrast_std_6  \n",
       "0               -0.778650           -0.453525            0.479612  \n",
       "1               -0.014905           -0.742246            0.318966  \n",
       "2               -0.166418           -1.076733           -0.265297  \n",
       "3               -0.584790           -0.472864           -0.260567  \n",
       "4               -0.658233           -0.090633            0.319449  \n",
       "...                   ...                 ...                 ...  \n",
       "99527           -0.613064            0.010541            0.138739  \n",
       "99528            0.106102           -0.789529            0.160393  \n",
       "99529            0.445736           -0.984278           -0.468615  \n",
       "99530           -1.174491           -0.516408            0.472931  \n",
       "99531            0.053349           -0.292865            0.016332  \n",
       "\n",
       "[99532 rows x 548 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "def sample_dataframe_by_single_threshold(hyper_param_threshold_idx):\n",
    "    dropped_indices = []\n",
    "\n",
    "    print(f'Total samples: {len(file_stand_incl_labels)}')\n",
    "    invalid_samples = 0\n",
    "    for i, sample in enumerate(file_stand_incl_labels.copy().to_numpy()[:, -7:]):\n",
    "        sample_has_nans = 0\n",
    "        sample_nan_idx = []\n",
    "        for l, val in enumerate(sample):\n",
    "            if math.isnan(val):\n",
    "                sample_nan_idx.append(l)\n",
    "                sample_has_nans += 1\n",
    "        # remove nans from sample\n",
    "        sample = np.delete(sample, sample_nan_idx)\n",
    "        # print(sample)\n",
    "        classes_vote = [np.count_nonzero((sample == 1) | (sample == 1.0)), np.count_nonzero((sample == 2) | (sample == 2.0)), np.count_nonzero((sample == 3) | (sample == 3.0)),\n",
    "                        np.count_nonzero((sample == 4) | (sample == 4.0)), np.count_nonzero((sample == 5) | (sample == 5.0)), np.count_nonzero((sample == 6) | (sample == 6.0))]\n",
    "        # accept fragments with no votes and votes above current threshold\n",
    "        if np.max(classes_vote) / len(sample) > 0:\n",
    "            if np.max(classes_vote) / len(sample) < hyper_param_threshold_idx:\n",
    "                invalid_samples += 1\n",
    "                dropped_indices.append(i)\n",
    "\n",
    "    print(f'Samples where annotators agree >= {hyper_param_threshold_idx*100}%: {len(file_stand_incl_labels) - invalid_samples} (dropped samples: {invalid_samples})')\n",
    "\n",
    "    # drop the samples with < threshold than selected\n",
    "    sampled_dataframe = file_stand_incl_labels.drop(dropped_indices).reset_index()\n",
    "    # drop vote columns and index_column\n",
    "    sampled_dataframe = sampled_dataframe.iloc[:, 1:-8]\n",
    "    return sampled_dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 120000\n",
      "Samples where annotators agree >= 71.42857142857143%: 96656 (dropped samples: 23344)\n"
     ]
    }
   ],
   "source": [
    "sampled_dataframe = sample_dataframe_by_single_threshold(hyper_param_threshold_idx=5/7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zcr_mean</th>\n",
       "      <th>zcr_std</th>\n",
       "      <th>yin_0</th>\n",
       "      <th>yin_1</th>\n",
       "      <th>yin_2</th>\n",
       "      <th>yin_3</th>\n",
       "      <th>yin_4</th>\n",
       "      <th>yin_5</th>\n",
       "      <th>yin_6</th>\n",
       "      <th>yin_7</th>\n",
       "      <th>...</th>\n",
       "      <th>cln_contrast_mean_4</th>\n",
       "      <th>cln_contrast_mean_5</th>\n",
       "      <th>cln_contrast_mean_6</th>\n",
       "      <th>cln_contrast_std_0</th>\n",
       "      <th>cln_contrast_std_1</th>\n",
       "      <th>cln_contrast_std_2</th>\n",
       "      <th>cln_contrast_std_3</th>\n",
       "      <th>cln_contrast_std_4</th>\n",
       "      <th>cln_contrast_std_5</th>\n",
       "      <th>cln_contrast_std_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.167208</td>\n",
       "      <td>-0.526000</td>\n",
       "      <td>-0.605283</td>\n",
       "      <td>-0.644997</td>\n",
       "      <td>-0.667503</td>\n",
       "      <td>-0.714700</td>\n",
       "      <td>-0.783143</td>\n",
       "      <td>-0.637137</td>\n",
       "      <td>-0.684710</td>\n",
       "      <td>-0.702930</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.427318</td>\n",
       "      <td>0.074920</td>\n",
       "      <td>-0.115683</td>\n",
       "      <td>0.804020</td>\n",
       "      <td>1.606063</td>\n",
       "      <td>-1.114032</td>\n",
       "      <td>-0.851041</td>\n",
       "      <td>-0.778650</td>\n",
       "      <td>-0.453525</td>\n",
       "      <td>0.479612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.461319</td>\n",
       "      <td>-0.636900</td>\n",
       "      <td>-0.578792</td>\n",
       "      <td>-0.649733</td>\n",
       "      <td>-0.671045</td>\n",
       "      <td>-0.717349</td>\n",
       "      <td>-0.780945</td>\n",
       "      <td>-0.636216</td>\n",
       "      <td>-0.683018</td>\n",
       "      <td>-0.700525</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.224404</td>\n",
       "      <td>-0.914364</td>\n",
       "      <td>-0.323859</td>\n",
       "      <td>-1.849531</td>\n",
       "      <td>1.352744</td>\n",
       "      <td>-0.486672</td>\n",
       "      <td>-1.106791</td>\n",
       "      <td>-0.014905</td>\n",
       "      <td>-0.742246</td>\n",
       "      <td>0.318966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.854948</td>\n",
       "      <td>-0.895040</td>\n",
       "      <td>-0.577355</td>\n",
       "      <td>-0.647228</td>\n",
       "      <td>1.701700</td>\n",
       "      <td>1.539210</td>\n",
       "      <td>1.367054</td>\n",
       "      <td>1.740341</td>\n",
       "      <td>1.636040</td>\n",
       "      <td>1.694016</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.778076</td>\n",
       "      <td>-0.928394</td>\n",
       "      <td>-0.319547</td>\n",
       "      <td>-0.412680</td>\n",
       "      <td>0.388380</td>\n",
       "      <td>0.980363</td>\n",
       "      <td>-0.796871</td>\n",
       "      <td>-0.166418</td>\n",
       "      <td>-1.076733</td>\n",
       "      <td>-0.265297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.822960</td>\n",
       "      <td>-0.542231</td>\n",
       "      <td>-0.608296</td>\n",
       "      <td>1.754146</td>\n",
       "      <td>1.784766</td>\n",
       "      <td>1.610830</td>\n",
       "      <td>1.431633</td>\n",
       "      <td>1.783958</td>\n",
       "      <td>1.649853</td>\n",
       "      <td>1.716896</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.623868</td>\n",
       "      <td>-1.209971</td>\n",
       "      <td>-0.311791</td>\n",
       "      <td>-0.557688</td>\n",
       "      <td>-0.121353</td>\n",
       "      <td>1.415610</td>\n",
       "      <td>-0.072873</td>\n",
       "      <td>-0.584790</td>\n",
       "      <td>-0.472864</td>\n",
       "      <td>-0.260567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.185489</td>\n",
       "      <td>-0.650381</td>\n",
       "      <td>1.920336</td>\n",
       "      <td>1.733858</td>\n",
       "      <td>1.769065</td>\n",
       "      <td>1.630653</td>\n",
       "      <td>1.431748</td>\n",
       "      <td>1.716913</td>\n",
       "      <td>1.575559</td>\n",
       "      <td>1.648439</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.204925</td>\n",
       "      <td>-1.441965</td>\n",
       "      <td>0.677037</td>\n",
       "      <td>-0.175322</td>\n",
       "      <td>-0.255244</td>\n",
       "      <td>0.513171</td>\n",
       "      <td>-1.169459</td>\n",
       "      <td>-0.658233</td>\n",
       "      <td>-0.090633</td>\n",
       "      <td>0.319449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96651</th>\n",
       "      <td>-0.331513</td>\n",
       "      <td>0.356134</td>\n",
       "      <td>-0.844403</td>\n",
       "      <td>-0.858645</td>\n",
       "      <td>-0.641962</td>\n",
       "      <td>-0.805758</td>\n",
       "      <td>-0.697388</td>\n",
       "      <td>-0.642756</td>\n",
       "      <td>-0.856450</td>\n",
       "      <td>-0.796840</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.286449</td>\n",
       "      <td>-0.457386</td>\n",
       "      <td>-0.313910</td>\n",
       "      <td>1.092455</td>\n",
       "      <td>-1.203601</td>\n",
       "      <td>0.934860</td>\n",
       "      <td>-0.202530</td>\n",
       "      <td>-0.613064</td>\n",
       "      <td>0.010541</td>\n",
       "      <td>0.138739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96652</th>\n",
       "      <td>-1.220233</td>\n",
       "      <td>-0.828050</td>\n",
       "      <td>-0.903588</td>\n",
       "      <td>-0.687250</td>\n",
       "      <td>-0.680983</td>\n",
       "      <td>-0.653949</td>\n",
       "      <td>-0.680398</td>\n",
       "      <td>-0.549913</td>\n",
       "      <td>-0.753115</td>\n",
       "      <td>-0.687278</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024849</td>\n",
       "      <td>-0.176945</td>\n",
       "      <td>-0.326877</td>\n",
       "      <td>0.339264</td>\n",
       "      <td>0.115136</td>\n",
       "      <td>-0.538031</td>\n",
       "      <td>1.039460</td>\n",
       "      <td>0.106102</td>\n",
       "      <td>-0.789529</td>\n",
       "      <td>0.160393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96653</th>\n",
       "      <td>-0.438986</td>\n",
       "      <td>-0.523291</td>\n",
       "      <td>-0.908066</td>\n",
       "      <td>-0.808672</td>\n",
       "      <td>-0.801250</td>\n",
       "      <td>-0.614802</td>\n",
       "      <td>-0.844231</td>\n",
       "      <td>-0.732196</td>\n",
       "      <td>-0.812538</td>\n",
       "      <td>-0.531270</td>\n",
       "      <td>...</td>\n",
       "      <td>0.102378</td>\n",
       "      <td>-0.428485</td>\n",
       "      <td>-0.163334</td>\n",
       "      <td>-0.339807</td>\n",
       "      <td>1.281501</td>\n",
       "      <td>1.089032</td>\n",
       "      <td>0.429298</td>\n",
       "      <td>0.445736</td>\n",
       "      <td>-0.984278</td>\n",
       "      <td>-0.468615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96654</th>\n",
       "      <td>-0.856478</td>\n",
       "      <td>-0.580928</td>\n",
       "      <td>-0.195463</td>\n",
       "      <td>-0.084748</td>\n",
       "      <td>-0.035737</td>\n",
       "      <td>-0.576595</td>\n",
       "      <td>-0.475360</td>\n",
       "      <td>-0.519312</td>\n",
       "      <td>-0.610353</td>\n",
       "      <td>-0.561646</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.584563</td>\n",
       "      <td>-0.117808</td>\n",
       "      <td>-0.142838</td>\n",
       "      <td>-0.283224</td>\n",
       "      <td>-0.190104</td>\n",
       "      <td>-0.195900</td>\n",
       "      <td>0.225551</td>\n",
       "      <td>-1.174491</td>\n",
       "      <td>-0.516408</td>\n",
       "      <td>0.472931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96655</th>\n",
       "      <td>-1.877472</td>\n",
       "      <td>0.710855</td>\n",
       "      <td>0.072642</td>\n",
       "      <td>-0.633977</td>\n",
       "      <td>-0.598054</td>\n",
       "      <td>-0.447791</td>\n",
       "      <td>-0.506353</td>\n",
       "      <td>-0.593066</td>\n",
       "      <td>-0.659019</td>\n",
       "      <td>-0.600411</td>\n",
       "      <td>...</td>\n",
       "      <td>0.150058</td>\n",
       "      <td>-0.102807</td>\n",
       "      <td>-0.238260</td>\n",
       "      <td>-1.239245</td>\n",
       "      <td>-0.300357</td>\n",
       "      <td>2.887519</td>\n",
       "      <td>-0.368612</td>\n",
       "      <td>0.053349</td>\n",
       "      <td>-0.292865</td>\n",
       "      <td>0.016332</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96656 rows × 548 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       zcr_mean   zcr_std     yin_0     yin_1     yin_2     yin_3     yin_4  \\\n",
       "0      0.167208 -0.526000 -0.605283 -0.644997 -0.667503 -0.714700 -0.783143   \n",
       "1      0.461319 -0.636900 -0.578792 -0.649733 -0.671045 -0.717349 -0.780945   \n",
       "2      0.854948 -0.895040 -0.577355 -0.647228  1.701700  1.539210  1.367054   \n",
       "3      0.822960 -0.542231 -0.608296  1.754146  1.784766  1.610830  1.431633   \n",
       "4      1.185489 -0.650381  1.920336  1.733858  1.769065  1.630653  1.431748   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "96651 -0.331513  0.356134 -0.844403 -0.858645 -0.641962 -0.805758 -0.697388   \n",
       "96652 -1.220233 -0.828050 -0.903588 -0.687250 -0.680983 -0.653949 -0.680398   \n",
       "96653 -0.438986 -0.523291 -0.908066 -0.808672 -0.801250 -0.614802 -0.844231   \n",
       "96654 -0.856478 -0.580928 -0.195463 -0.084748 -0.035737 -0.576595 -0.475360   \n",
       "96655 -1.877472  0.710855  0.072642 -0.633977 -0.598054 -0.447791 -0.506353   \n",
       "\n",
       "          yin_5     yin_6     yin_7  ...  cln_contrast_mean_4  \\\n",
       "0     -0.637137 -0.684710 -0.702930  ...            -1.427318   \n",
       "1     -0.636216 -0.683018 -0.700525  ...            -0.224404   \n",
       "2      1.740341  1.636040  1.694016  ...            -0.778076   \n",
       "3      1.783958  1.649853  1.716896  ...            -1.623868   \n",
       "4      1.716913  1.575559  1.648439  ...            -0.204925   \n",
       "...         ...       ...       ...  ...                  ...   \n",
       "96651 -0.642756 -0.856450 -0.796840  ...            -0.286449   \n",
       "96652 -0.549913 -0.753115 -0.687278  ...             0.024849   \n",
       "96653 -0.732196 -0.812538 -0.531270  ...             0.102378   \n",
       "96654 -0.519312 -0.610353 -0.561646  ...            -0.584563   \n",
       "96655 -0.593066 -0.659019 -0.600411  ...             0.150058   \n",
       "\n",
       "       cln_contrast_mean_5  cln_contrast_mean_6  cln_contrast_std_0  \\\n",
       "0                 0.074920            -0.115683            0.804020   \n",
       "1                -0.914364            -0.323859           -1.849531   \n",
       "2                -0.928394            -0.319547           -0.412680   \n",
       "3                -1.209971            -0.311791           -0.557688   \n",
       "4                -1.441965             0.677037           -0.175322   \n",
       "...                    ...                  ...                 ...   \n",
       "96651            -0.457386            -0.313910            1.092455   \n",
       "96652            -0.176945            -0.326877            0.339264   \n",
       "96653            -0.428485            -0.163334           -0.339807   \n",
       "96654            -0.117808            -0.142838           -0.283224   \n",
       "96655            -0.102807            -0.238260           -1.239245   \n",
       "\n",
       "       cln_contrast_std_1  cln_contrast_std_2  cln_contrast_std_3  \\\n",
       "0                1.606063           -1.114032           -0.851041   \n",
       "1                1.352744           -0.486672           -1.106791   \n",
       "2                0.388380            0.980363           -0.796871   \n",
       "3               -0.121353            1.415610           -0.072873   \n",
       "4               -0.255244            0.513171           -1.169459   \n",
       "...                   ...                 ...                 ...   \n",
       "96651           -1.203601            0.934860           -0.202530   \n",
       "96652            0.115136           -0.538031            1.039460   \n",
       "96653            1.281501            1.089032            0.429298   \n",
       "96654           -0.190104           -0.195900            0.225551   \n",
       "96655           -0.300357            2.887519           -0.368612   \n",
       "\n",
       "       cln_contrast_std_4  cln_contrast_std_5  cln_contrast_std_6  \n",
       "0               -0.778650           -0.453525            0.479612  \n",
       "1               -0.014905           -0.742246            0.318966  \n",
       "2               -0.166418           -1.076733           -0.265297  \n",
       "3               -0.584790           -0.472864           -0.260567  \n",
       "4               -0.658233           -0.090633            0.319449  \n",
       "...                   ...                 ...                 ...  \n",
       "96651           -0.613064            0.010541            0.138739  \n",
       "96652            0.106102           -0.789529            0.160393  \n",
       "96653            0.445736           -0.984278           -0.468615  \n",
       "96654           -1.174491           -0.516408            0.472931  \n",
       "96655            0.053349           -0.292865            0.016332  \n",
       "\n",
       "[96656 rows x 548 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "_annotations = [\n",
    "    [2/3, 3/4, 4/5, 4/6, 4/7], # majority voteing\n",
    "    [2/3, 3/4, 4/5, 4/6, 5/7], # out voteing\n",
    "    [2/3, 3/4, 4/5, 5/6, 5/7], # higher majority\n",
    "    [2/3, 3/4, 4/5, 5/6, 6/7], # at most one wrong\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "def sample_dataframe_by_thresholds(hyper_param_thresholds):\n",
    "    dropped_indices = []\n",
    "    nr_annotators = [0, 0, 0, 0, 0]\n",
    "    _return_val = []\n",
    "    #print(f'Total samples: {len(file_stand_incl_labels)}')\n",
    "    for n, threshold in enumerate(hyper_param_thresholds):\n",
    "        invalid_samples = 0\n",
    "        inner_list_dropped_indices = []\n",
    "        dropped_indices = []\n",
    "        \n",
    "        for i, sample in enumerate(file_stand_incl_labels.copy().to_numpy()[:, -7:]):\n",
    "            sample_has_nans = 0\n",
    "            sample_nan_idx = []\n",
    "            for l, val in enumerate(sample):\n",
    "                if math.isnan(val):\n",
    "                    sample_nan_idx.append(l)\n",
    "                    sample_has_nans += 1\n",
    "            # remove nans from sample\n",
    "            sample = np.delete(sample, sample_nan_idx)\n",
    "            # print(sample)\n",
    "            classes_vote = [np.count_nonzero((sample == 1) | (sample == 1.0)), np.count_nonzero((sample == 2) | (sample == 2.0)), np.count_nonzero((sample == 3) | (sample == 3.0)),\n",
    "                            np.count_nonzero((sample == 4) | (sample == 4.0)), np.count_nonzero((sample == 5) | (sample == 5.0)), np.count_nonzero((sample == 6) | (sample == 6.0))]\n",
    "            # accept fragments with no votes and votes above current threshold\n",
    "            if np.max(classes_vote) / len(sample) > 0:\n",
    "                if len(sample) == 3 and np.max(classes_vote) / len(sample) < threshold:\n",
    "                    invalid_samples += 1\n",
    "                    inner_list_dropped_indices.append(i)\n",
    "                    nr_annotators[0] += 1\n",
    "                elif len(sample) == 4 and np.max(classes_vote) / len(sample) < threshold:\n",
    "                    invalid_samples += 1\n",
    "                    inner_list_dropped_indices.append(i)\n",
    "                    nr_annotators[1] += 1\n",
    "                elif len(sample) == 5 and np.max(classes_vote) / len(sample) < threshold:\n",
    "                    invalid_samples += 1\n",
    "                    inner_list_dropped_indices.append(i)\n",
    "                    nr_annotators[2] += 1\n",
    "                elif len(sample) == 6 and np.max(classes_vote) / len(sample) < threshold:\n",
    "                    invalid_samples += 1\n",
    "                    inner_list_dropped_indices.append(i)\n",
    "                    nr_annotators[3] += 1\n",
    "                elif len(sample) == 7 and np.max(classes_vote) / len(sample) < threshold:\n",
    "                    invalid_samples += 1\n",
    "                    inner_list_dropped_indices.append(i)\n",
    "                    nr_annotators[4] += 1\n",
    "        dropped_indices.append(inner_list_dropped_indices)\n",
    "        print(f'Samples where annotators agree >= {threshold*100}%: {len(file_stand_incl_labels) - invalid_samples} (dropped samples: {invalid_samples})')\n",
    "        _return_val.append(len(file_stand_incl_labels) - invalid_samples)\n",
    "        #print(len(file_stand_incl_labels) - invalid_samples)\n",
    "    return hyper_param_thresholds, _return_val\n",
    "    # drop the samples with < threshold than selected    \n",
    "    #sampled_dataframe = file_stand_incl_labels.drop(dropped_indices[hyper_param_threshold_idx]).reset_index()\n",
    "    # drop vote columns and index_column\n",
    "    #sampled_dataframe = sampled_dataframe.iloc[:, 1:-8]\n",
    "    #print(nr_annotators)\n",
    "    #return sampled_dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples where annotators agree >= 66.66666666666666%: 99013 (dropped samples: 20987)\n",
      "Samples where annotators agree >= 75.0%: 93903 (dropped samples: 26097)\n",
      "Samples where annotators agree >= 80.0%: 93903 (dropped samples: 26097)\n",
      "Samples where annotators agree >= 66.66666666666666%: 99013 (dropped samples: 20987)\n",
      "Samples where annotators agree >= 71.42857142857143%: 96656 (dropped samples: 23344)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.6666666666666666, 0.75, 0.8, 0.6666666666666666, 0.7142857142857143],\n",
       " [99013, 93903, 93903, 99013, 96656])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_dataframe_by_thresholds(hyper_param_thresholds=[2/3, 3/4, 4/5, 4/6, 5/7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[0.6666666666666666, 0.75, 0.8, 0.6666666666666666, 0.5714285714285714]\n",
      "Samples where annotators agree >= 66.66666666666666%: 99013 (dropped samples: 20987)\n",
      "Samples where annotators agree >= 75.0%: 93903 (dropped samples: 26097)\n",
      "Samples where annotators agree >= 80.0%: 93903 (dropped samples: 26097)\n",
      "Samples where annotators agree >= 66.66666666666666%: 99013 (dropped samples: 20987)\n",
      "Samples where annotators agree >= 57.14285714285714%: 101648 (dropped samples: 18352)\n",
      "\n",
      "[0.6666666666666666, 0.75, 0.8, 0.6666666666666666, 0.7142857142857143]\n",
      "Samples where annotators agree >= 66.66666666666666%: 99013 (dropped samples: 20987)\n",
      "Samples where annotators agree >= 75.0%: 93903 (dropped samples: 26097)\n",
      "Samples where annotators agree >= 80.0%: 93903 (dropped samples: 26097)\n",
      "Samples where annotators agree >= 66.66666666666666%: 99013 (dropped samples: 20987)\n",
      "Samples where annotators agree >= 71.42857142857143%: 96656 (dropped samples: 23344)\n",
      "\n",
      "[0.6666666666666666, 0.75, 0.8, 0.8333333333333334, 0.7142857142857143]\n",
      "Samples where annotators agree >= 66.66666666666666%: 99013 (dropped samples: 20987)\n",
      "Samples where annotators agree >= 75.0%: 93903 (dropped samples: 26097)\n",
      "Samples where annotators agree >= 80.0%: 93903 (dropped samples: 26097)\n",
      "Samples where annotators agree >= 83.33333333333334%: 92372 (dropped samples: 27628)\n",
      "Samples where annotators agree >= 71.42857142857143%: 96656 (dropped samples: 23344)\n",
      "\n",
      "[0.6666666666666666, 0.75, 0.8, 0.8333333333333334, 0.8571428571428571]\n",
      "Samples where annotators agree >= 66.66666666666666%: 99013 (dropped samples: 20987)\n",
      "Samples where annotators agree >= 75.0%: 93903 (dropped samples: 26097)\n",
      "Samples where annotators agree >= 80.0%: 93903 (dropped samples: 26097)\n",
      "Samples where annotators agree >= 83.33333333333334%: 92372 (dropped samples: 27628)\n",
      "Samples where annotators agree >= 85.71428571428571%: 89474 (dropped samples: 30526)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x720 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_annotations = [\n",
    "    [2/3, 3/4, 4/5, 4/6, 4/7], # majority voteing\n",
    "    [2/3, 3/4, 4/5, 4/6, 5/7], # out voteing\n",
    "    [2/3, 3/4, 4/5, 5/6, 5/7], # higher majority\n",
    "    [2/3, 3/4, 4/5, 5/6, 6/7], # at most one wrong\n",
    "]\n",
    "\n",
    "fig, axis = plt.subplots(4, figsize=(10, 10))\n",
    "for i, thr in enumerate(_annotations):\n",
    "    print()\n",
    "    print(thr)\n",
    "    _, y = sample_dataframe_by_thresholds(hyper_param_thresholds=thr)\n",
    "    #y = [99013, 93903, 93903, 99013, 101648]\n",
    "    #x = [str(2/3), str(3/4), str(4/5), str(4/6), str(4/7)]\n",
    "    x = [str(_x) for _x in thr]\n",
    "\n",
    "    axis[i].bar(x, y)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "def sample_dataframe_by_threshold():\n",
    "    dropped_indices = []\n",
    "    nr_annotators = [0, 0, 0, 0, 0]\n",
    "\n",
    "    invalid_samples = 0\n",
    "    for i, sample in enumerate(file_stand_incl_labels.copy().to_numpy()[:, -7:]):\n",
    "        sample_has_nans = 0\n",
    "        sample_nan_idx = []\n",
    "        for l, val in enumerate(sample):\n",
    "            if math.isnan(val):\n",
    "                sample_nan_idx.append(l)\n",
    "                sample_has_nans += 1\n",
    "        # remove nans from sample\n",
    "        sample = np.delete(sample, sample_nan_idx)\n",
    "        # print(sample)\n",
    "        classes_vote = [np.count_nonzero((sample == 1) | (sample == 1.0)), np.count_nonzero((sample == 2) | (sample == 2.0)), np.count_nonzero((sample == 3) | (sample == 3.0)),\n",
    "                        np.count_nonzero((sample == 4) | (sample == 4.0)), np.count_nonzero((sample == 5) | (sample == 5.0)), np.count_nonzero((sample == 6) | (sample == 6.0))]\n",
    "        # accept fragments with no votes and votes above current threshold\n",
    "        if np.max(classes_vote) / len(sample) > 0:\n",
    "            #accept all samples for 3 annotators\n",
    "            \"\"\"if len(sample) == 3 and np.max(classes_vote) / len(sample) < 3/3:\n",
    "                invalid_samples += 1\n",
    "                inner_list_dropped_indices.append(i)\n",
    "                nr_annotators[0] += 1\"\"\"\n",
    "            if len(sample) == 4 and np.max(classes_vote) / len(sample) < 3/4:\n",
    "                invalid_samples += 1\n",
    "                dropped_indices.append(i)\n",
    "                nr_annotators[1] += 1\n",
    "            elif len(sample) == 5 and np.max(classes_vote) / len(sample) < 3/5:\n",
    "                invalid_samples += 1\n",
    "                dropped_indices.append(i)\n",
    "                nr_annotators[2] += 1\n",
    "            elif len(sample) == 6 and np.max(classes_vote) / len(sample) < 4/6:\n",
    "                invalid_samples += 1\n",
    "                dropped_indices.append(i)\n",
    "                nr_annotators[3] += 1\n",
    "            elif len(sample) == 7 and np.max(classes_vote) / len(sample) < 5/7:\n",
    "                invalid_samples += 1\n",
    "                dropped_indices.append(i)\n",
    "                nr_annotators[4] += 1\n",
    "    # drop the samples with < threshold than selected\n",
    "    sampled_dataframe = file_stand_incl_labels.drop(dropped_indices).reset_index()\n",
    "    # drop vote columns and index_column\n",
    "    sampled_dataframe = sampled_dataframe.iloc[:, 1:-8]\n",
    "    #print(nr_annotators)\n",
    "    return sampled_dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 1557, 7220, 11475]\n"
     ]
    }
   ],
   "source": [
    "sampled_dataframe = sample_dataframe_by_threshold()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zcr_mean</th>\n",
       "      <th>zcr_std</th>\n",
       "      <th>yin_0</th>\n",
       "      <th>yin_1</th>\n",
       "      <th>yin_2</th>\n",
       "      <th>yin_3</th>\n",
       "      <th>yin_4</th>\n",
       "      <th>yin_5</th>\n",
       "      <th>yin_6</th>\n",
       "      <th>yin_7</th>\n",
       "      <th>...</th>\n",
       "      <th>cln_contrast_mean_4</th>\n",
       "      <th>cln_contrast_mean_5</th>\n",
       "      <th>cln_contrast_mean_6</th>\n",
       "      <th>cln_contrast_std_0</th>\n",
       "      <th>cln_contrast_std_1</th>\n",
       "      <th>cln_contrast_std_2</th>\n",
       "      <th>cln_contrast_std_3</th>\n",
       "      <th>cln_contrast_std_4</th>\n",
       "      <th>cln_contrast_std_5</th>\n",
       "      <th>cln_contrast_std_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.167208</td>\n",
       "      <td>-0.526000</td>\n",
       "      <td>-0.605283</td>\n",
       "      <td>-0.644997</td>\n",
       "      <td>-0.667503</td>\n",
       "      <td>-0.714700</td>\n",
       "      <td>-0.783143</td>\n",
       "      <td>-0.637137</td>\n",
       "      <td>-0.684710</td>\n",
       "      <td>-0.702930</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.427318</td>\n",
       "      <td>0.074920</td>\n",
       "      <td>-0.115683</td>\n",
       "      <td>0.804020</td>\n",
       "      <td>1.606063</td>\n",
       "      <td>-1.114032</td>\n",
       "      <td>-0.851041</td>\n",
       "      <td>-0.778650</td>\n",
       "      <td>-0.453525</td>\n",
       "      <td>0.479612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.461319</td>\n",
       "      <td>-0.636900</td>\n",
       "      <td>-0.578792</td>\n",
       "      <td>-0.649733</td>\n",
       "      <td>-0.671045</td>\n",
       "      <td>-0.717349</td>\n",
       "      <td>-0.780945</td>\n",
       "      <td>-0.636216</td>\n",
       "      <td>-0.683018</td>\n",
       "      <td>-0.700525</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.224404</td>\n",
       "      <td>-0.914364</td>\n",
       "      <td>-0.323859</td>\n",
       "      <td>-1.849531</td>\n",
       "      <td>1.352744</td>\n",
       "      <td>-0.486672</td>\n",
       "      <td>-1.106791</td>\n",
       "      <td>-0.014905</td>\n",
       "      <td>-0.742246</td>\n",
       "      <td>0.318966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.854948</td>\n",
       "      <td>-0.895040</td>\n",
       "      <td>-0.577355</td>\n",
       "      <td>-0.647228</td>\n",
       "      <td>1.701700</td>\n",
       "      <td>1.539210</td>\n",
       "      <td>1.367054</td>\n",
       "      <td>1.740341</td>\n",
       "      <td>1.636040</td>\n",
       "      <td>1.694016</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.778076</td>\n",
       "      <td>-0.928394</td>\n",
       "      <td>-0.319547</td>\n",
       "      <td>-0.412680</td>\n",
       "      <td>0.388380</td>\n",
       "      <td>0.980363</td>\n",
       "      <td>-0.796871</td>\n",
       "      <td>-0.166418</td>\n",
       "      <td>-1.076733</td>\n",
       "      <td>-0.265297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.822960</td>\n",
       "      <td>-0.542231</td>\n",
       "      <td>-0.608296</td>\n",
       "      <td>1.754146</td>\n",
       "      <td>1.784766</td>\n",
       "      <td>1.610830</td>\n",
       "      <td>1.431633</td>\n",
       "      <td>1.783958</td>\n",
       "      <td>1.649853</td>\n",
       "      <td>1.716896</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.623868</td>\n",
       "      <td>-1.209971</td>\n",
       "      <td>-0.311791</td>\n",
       "      <td>-0.557688</td>\n",
       "      <td>-0.121353</td>\n",
       "      <td>1.415610</td>\n",
       "      <td>-0.072873</td>\n",
       "      <td>-0.584790</td>\n",
       "      <td>-0.472864</td>\n",
       "      <td>-0.260567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.185489</td>\n",
       "      <td>-0.650381</td>\n",
       "      <td>1.920336</td>\n",
       "      <td>1.733858</td>\n",
       "      <td>1.769065</td>\n",
       "      <td>1.630653</td>\n",
       "      <td>1.431748</td>\n",
       "      <td>1.716913</td>\n",
       "      <td>1.575559</td>\n",
       "      <td>1.648439</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.204925</td>\n",
       "      <td>-1.441965</td>\n",
       "      <td>0.677037</td>\n",
       "      <td>-0.175322</td>\n",
       "      <td>-0.255244</td>\n",
       "      <td>0.513171</td>\n",
       "      <td>-1.169459</td>\n",
       "      <td>-0.658233</td>\n",
       "      <td>-0.090633</td>\n",
       "      <td>0.319449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99743</th>\n",
       "      <td>-0.331513</td>\n",
       "      <td>0.356134</td>\n",
       "      <td>-0.844403</td>\n",
       "      <td>-0.858645</td>\n",
       "      <td>-0.641962</td>\n",
       "      <td>-0.805758</td>\n",
       "      <td>-0.697388</td>\n",
       "      <td>-0.642756</td>\n",
       "      <td>-0.856450</td>\n",
       "      <td>-0.796840</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.286449</td>\n",
       "      <td>-0.457386</td>\n",
       "      <td>-0.313910</td>\n",
       "      <td>1.092455</td>\n",
       "      <td>-1.203601</td>\n",
       "      <td>0.934860</td>\n",
       "      <td>-0.202530</td>\n",
       "      <td>-0.613064</td>\n",
       "      <td>0.010541</td>\n",
       "      <td>0.138739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99744</th>\n",
       "      <td>-1.220233</td>\n",
       "      <td>-0.828050</td>\n",
       "      <td>-0.903588</td>\n",
       "      <td>-0.687250</td>\n",
       "      <td>-0.680983</td>\n",
       "      <td>-0.653949</td>\n",
       "      <td>-0.680398</td>\n",
       "      <td>-0.549913</td>\n",
       "      <td>-0.753115</td>\n",
       "      <td>-0.687278</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024849</td>\n",
       "      <td>-0.176945</td>\n",
       "      <td>-0.326877</td>\n",
       "      <td>0.339264</td>\n",
       "      <td>0.115136</td>\n",
       "      <td>-0.538031</td>\n",
       "      <td>1.039460</td>\n",
       "      <td>0.106102</td>\n",
       "      <td>-0.789529</td>\n",
       "      <td>0.160393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99745</th>\n",
       "      <td>-0.438986</td>\n",
       "      <td>-0.523291</td>\n",
       "      <td>-0.908066</td>\n",
       "      <td>-0.808672</td>\n",
       "      <td>-0.801250</td>\n",
       "      <td>-0.614802</td>\n",
       "      <td>-0.844231</td>\n",
       "      <td>-0.732196</td>\n",
       "      <td>-0.812538</td>\n",
       "      <td>-0.531270</td>\n",
       "      <td>...</td>\n",
       "      <td>0.102378</td>\n",
       "      <td>-0.428485</td>\n",
       "      <td>-0.163334</td>\n",
       "      <td>-0.339807</td>\n",
       "      <td>1.281501</td>\n",
       "      <td>1.089032</td>\n",
       "      <td>0.429298</td>\n",
       "      <td>0.445736</td>\n",
       "      <td>-0.984278</td>\n",
       "      <td>-0.468615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99746</th>\n",
       "      <td>-0.856478</td>\n",
       "      <td>-0.580928</td>\n",
       "      <td>-0.195463</td>\n",
       "      <td>-0.084748</td>\n",
       "      <td>-0.035737</td>\n",
       "      <td>-0.576595</td>\n",
       "      <td>-0.475360</td>\n",
       "      <td>-0.519312</td>\n",
       "      <td>-0.610353</td>\n",
       "      <td>-0.561646</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.584563</td>\n",
       "      <td>-0.117808</td>\n",
       "      <td>-0.142838</td>\n",
       "      <td>-0.283224</td>\n",
       "      <td>-0.190104</td>\n",
       "      <td>-0.195900</td>\n",
       "      <td>0.225551</td>\n",
       "      <td>-1.174491</td>\n",
       "      <td>-0.516408</td>\n",
       "      <td>0.472931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99747</th>\n",
       "      <td>-1.877472</td>\n",
       "      <td>0.710855</td>\n",
       "      <td>0.072642</td>\n",
       "      <td>-0.633977</td>\n",
       "      <td>-0.598054</td>\n",
       "      <td>-0.447791</td>\n",
       "      <td>-0.506353</td>\n",
       "      <td>-0.593066</td>\n",
       "      <td>-0.659019</td>\n",
       "      <td>-0.600411</td>\n",
       "      <td>...</td>\n",
       "      <td>0.150058</td>\n",
       "      <td>-0.102807</td>\n",
       "      <td>-0.238260</td>\n",
       "      <td>-1.239245</td>\n",
       "      <td>-0.300357</td>\n",
       "      <td>2.887519</td>\n",
       "      <td>-0.368612</td>\n",
       "      <td>0.053349</td>\n",
       "      <td>-0.292865</td>\n",
       "      <td>0.016332</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99748 rows × 548 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       zcr_mean   zcr_std     yin_0     yin_1     yin_2     yin_3     yin_4  \\\n",
       "0      0.167208 -0.526000 -0.605283 -0.644997 -0.667503 -0.714700 -0.783143   \n",
       "1      0.461319 -0.636900 -0.578792 -0.649733 -0.671045 -0.717349 -0.780945   \n",
       "2      0.854948 -0.895040 -0.577355 -0.647228  1.701700  1.539210  1.367054   \n",
       "3      0.822960 -0.542231 -0.608296  1.754146  1.784766  1.610830  1.431633   \n",
       "4      1.185489 -0.650381  1.920336  1.733858  1.769065  1.630653  1.431748   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "99743 -0.331513  0.356134 -0.844403 -0.858645 -0.641962 -0.805758 -0.697388   \n",
       "99744 -1.220233 -0.828050 -0.903588 -0.687250 -0.680983 -0.653949 -0.680398   \n",
       "99745 -0.438986 -0.523291 -0.908066 -0.808672 -0.801250 -0.614802 -0.844231   \n",
       "99746 -0.856478 -0.580928 -0.195463 -0.084748 -0.035737 -0.576595 -0.475360   \n",
       "99747 -1.877472  0.710855  0.072642 -0.633977 -0.598054 -0.447791 -0.506353   \n",
       "\n",
       "          yin_5     yin_6     yin_7  ...  cln_contrast_mean_4  \\\n",
       "0     -0.637137 -0.684710 -0.702930  ...            -1.427318   \n",
       "1     -0.636216 -0.683018 -0.700525  ...            -0.224404   \n",
       "2      1.740341  1.636040  1.694016  ...            -0.778076   \n",
       "3      1.783958  1.649853  1.716896  ...            -1.623868   \n",
       "4      1.716913  1.575559  1.648439  ...            -0.204925   \n",
       "...         ...       ...       ...  ...                  ...   \n",
       "99743 -0.642756 -0.856450 -0.796840  ...            -0.286449   \n",
       "99744 -0.549913 -0.753115 -0.687278  ...             0.024849   \n",
       "99745 -0.732196 -0.812538 -0.531270  ...             0.102378   \n",
       "99746 -0.519312 -0.610353 -0.561646  ...            -0.584563   \n",
       "99747 -0.593066 -0.659019 -0.600411  ...             0.150058   \n",
       "\n",
       "       cln_contrast_mean_5  cln_contrast_mean_6  cln_contrast_std_0  \\\n",
       "0                 0.074920            -0.115683            0.804020   \n",
       "1                -0.914364            -0.323859           -1.849531   \n",
       "2                -0.928394            -0.319547           -0.412680   \n",
       "3                -1.209971            -0.311791           -0.557688   \n",
       "4                -1.441965             0.677037           -0.175322   \n",
       "...                    ...                  ...                 ...   \n",
       "99743            -0.457386            -0.313910            1.092455   \n",
       "99744            -0.176945            -0.326877            0.339264   \n",
       "99745            -0.428485            -0.163334           -0.339807   \n",
       "99746            -0.117808            -0.142838           -0.283224   \n",
       "99747            -0.102807            -0.238260           -1.239245   \n",
       "\n",
       "       cln_contrast_std_1  cln_contrast_std_2  cln_contrast_std_3  \\\n",
       "0                1.606063           -1.114032           -0.851041   \n",
       "1                1.352744           -0.486672           -1.106791   \n",
       "2                0.388380            0.980363           -0.796871   \n",
       "3               -0.121353            1.415610           -0.072873   \n",
       "4               -0.255244            0.513171           -1.169459   \n",
       "...                   ...                 ...                 ...   \n",
       "99743           -1.203601            0.934860           -0.202530   \n",
       "99744            0.115136           -0.538031            1.039460   \n",
       "99745            1.281501            1.089032            0.429298   \n",
       "99746           -0.190104           -0.195900            0.225551   \n",
       "99747           -0.300357            2.887519           -0.368612   \n",
       "\n",
       "       cln_contrast_std_4  cln_contrast_std_5  cln_contrast_std_6  \n",
       "0               -0.778650           -0.453525            0.479612  \n",
       "1               -0.014905           -0.742246            0.318966  \n",
       "2               -0.166418           -1.076733           -0.265297  \n",
       "3               -0.584790           -0.472864           -0.260567  \n",
       "4               -0.658233           -0.090633            0.319449  \n",
       "...                   ...                 ...                 ...  \n",
       "99743           -0.613064            0.010541            0.138739  \n",
       "99744            0.106102           -0.789529            0.160393  \n",
       "99745            0.445736           -0.984278           -0.468615  \n",
       "99746           -1.174491           -0.516408            0.472931  \n",
       "99747            0.053349           -0.292865            0.016332  \n",
       "\n",
       "[99748 rows x 548 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ho2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
