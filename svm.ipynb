{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os, glob\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "np.random.seed(1234)\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Data Laoding</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('trainset_python/python/class_names.txt') as f:\n",
    "    classes = f.readlines()\n",
    "\n",
    "for i,c in enumerate(classes):\n",
    "    classes[i] = c.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('trainset_python/python/feature_names.txt') as f:\n",
    "    features = f.readlines()\n",
    "\n",
    "for i,feature in enumerate(features):\n",
    "    features[i] = feature.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all files in one dataframe\n",
    "idx = pd.Series([i for i in range(100)])\n",
    "\n",
    "rootdir = os. getcwd()\n",
    "files = pd.DataFrame([])\n",
    "files_stand = pd.DataFrame([])\n",
    "lables = pd.DataFrame([])\n",
    "data = pd.DataFrame([])\n",
    "data_stand = pd.DataFrame([])\n",
    "    \n",
    "for i,f in enumerate(glob.glob(rootdir + '/**/*.npy', recursive=True)):\n",
    "    if (i % 2) == 0:\n",
    "        lable = pd.DataFrame(np.load(f))\n",
    "        #lable = lable.rename(columns={lable.columns[0]: \"overall_class\"})\n",
    "        for i, col in enumerate(lable.columns):\n",
    "            if i == 0:\n",
    "                lable = lable.rename(columns={lable.columns[0]: \"overall_class_vote\"})\n",
    "            else:\n",
    "                lable = lable.rename(columns={col: \"class_vote_\" + str(i)})\n",
    "        if lables.empty:\n",
    "            lables = lable\n",
    "        else:\n",
    "            idx = idx + (i*100)\n",
    "            lable.index = idx\n",
    "            lables = lables.append(lable)\n",
    "    else:\n",
    "        file = pd.DataFrame(np.load(f), columns = features)\n",
    "        file_stand = pd.DataFrame(StandardScaler().fit_transform(np.load(f)), columns = features)\n",
    "        if files.empty:\n",
    "            files = file\n",
    "        else:\n",
    "            idx = idx + (i*100)\n",
    "            file.index = idx\n",
    "            files = files.append(file)\n",
    "        if files_stand.empty:\n",
    "            files_stand = file_stand\n",
    "        else:\n",
    "            idx = idx + (i*100)\n",
    "            file_stand.index = idx\n",
    "            files_stand = files_stand.append(file_stand)\n",
    "\n",
    "\n",
    "lables.index = pd.Series([i for i in range(len(lables))])\n",
    "files.index = pd.Series([i for i in range(len(lables))])\n",
    "files_stand.index = pd.Series([i for i in range(len(lables))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_stand_incl_labels = pd.concat([files_stand, lables], axis=1, join='inner')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Sample data</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def sample_dataframe_by_threshold(file_stand_incl_labels, lables):\n",
    "    dropped_indices = []\n",
    "    nr_annotators = [0, 0, 0, 0, 0]\n",
    "\n",
    "    invalid_samples = 0\n",
    "    for i, sample in enumerate(file_stand_incl_labels.copy().to_numpy()[:, -7:]):\n",
    "        sample_has_nans = 0\n",
    "        sample_nan_idx = []\n",
    "        for l, val in enumerate(sample):\n",
    "            if math.isnan(val):\n",
    "                sample_nan_idx.append(l)\n",
    "                sample_has_nans += 1\n",
    "        # remove nans from sample\n",
    "        sample = np.delete(sample, sample_nan_idx)\n",
    "        # print(sample)\n",
    "        classes_vote = [np.count_nonzero((sample == 1) | (sample == 1.0)), np.count_nonzero((sample == 2) | (sample == 2.0)), np.count_nonzero((sample == 3) | (sample == 3.0)),\n",
    "                        np.count_nonzero((sample == 4) | (sample == 4.0)), np.count_nonzero((sample == 5) | (sample == 5.0)), np.count_nonzero((sample == 6) | (sample == 6.0))]\n",
    "        # accept fragments with no votes and votes above current threshold\n",
    "        if np.max(classes_vote) / len(sample) > 0:\n",
    "            #accept all samples for 3 annotators\n",
    "            if len(sample) == 4 and np.max(classes_vote) / len(sample) < 3/4:\n",
    "                invalid_samples += 1\n",
    "                dropped_indices.append(i)\n",
    "            elif len(sample) == 5 and np.max(classes_vote) / len(sample) < 3/5:\n",
    "                invalid_samples += 1\n",
    "                dropped_indices.append(i)\n",
    "            elif len(sample) == 6 and np.max(classes_vote) / len(sample) < 4/6:\n",
    "                invalid_samples += 1\n",
    "                dropped_indices.append(i)\n",
    "            elif len(sample) == 7 and np.max(classes_vote) / len(sample) < 5/7:\n",
    "                invalid_samples += 1\n",
    "                dropped_indices.append(i)\n",
    "    # drop the samples with < threshold than selected\n",
    "    sampled_dataframe = file_stand_incl_labels.drop(dropped_indices).reset_index()\n",
    "    lables_agree = lables.drop(dropped_indices).reset_index()\n",
    "    lables_agree = lables_agree.iloc[:, 1:]\n",
    "    # drop vote columns and index_column\n",
    "    sampled_dataframe = sampled_dataframe.iloc[:, 1:-8]\n",
    "    return sampled_dataframe, lables_agree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_agree, lables_agree = sample_dataframe_by_threshold(file_stand_incl_labels, lables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zcr_mean</th>\n",
       "      <th>zcr_std</th>\n",
       "      <th>yin_0</th>\n",
       "      <th>yin_1</th>\n",
       "      <th>yin_2</th>\n",
       "      <th>yin_3</th>\n",
       "      <th>yin_4</th>\n",
       "      <th>yin_5</th>\n",
       "      <th>yin_6</th>\n",
       "      <th>yin_7</th>\n",
       "      <th>...</th>\n",
       "      <th>cln_contrast_mean_4</th>\n",
       "      <th>cln_contrast_mean_5</th>\n",
       "      <th>cln_contrast_mean_6</th>\n",
       "      <th>cln_contrast_std_0</th>\n",
       "      <th>cln_contrast_std_1</th>\n",
       "      <th>cln_contrast_std_2</th>\n",
       "      <th>cln_contrast_std_3</th>\n",
       "      <th>cln_contrast_std_4</th>\n",
       "      <th>cln_contrast_std_5</th>\n",
       "      <th>cln_contrast_std_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.167208</td>\n",
       "      <td>-0.526000</td>\n",
       "      <td>-0.605283</td>\n",
       "      <td>-0.644997</td>\n",
       "      <td>-0.667503</td>\n",
       "      <td>-0.714700</td>\n",
       "      <td>-0.783143</td>\n",
       "      <td>-0.637137</td>\n",
       "      <td>-0.684710</td>\n",
       "      <td>-0.702930</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.427318</td>\n",
       "      <td>0.074920</td>\n",
       "      <td>-0.115683</td>\n",
       "      <td>0.804020</td>\n",
       "      <td>1.606063</td>\n",
       "      <td>-1.114032</td>\n",
       "      <td>-0.851041</td>\n",
       "      <td>-0.778650</td>\n",
       "      <td>-0.453525</td>\n",
       "      <td>0.479612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.461319</td>\n",
       "      <td>-0.636900</td>\n",
       "      <td>-0.578792</td>\n",
       "      <td>-0.649733</td>\n",
       "      <td>-0.671045</td>\n",
       "      <td>-0.717349</td>\n",
       "      <td>-0.780945</td>\n",
       "      <td>-0.636216</td>\n",
       "      <td>-0.683018</td>\n",
       "      <td>-0.700525</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.224404</td>\n",
       "      <td>-0.914364</td>\n",
       "      <td>-0.323859</td>\n",
       "      <td>-1.849531</td>\n",
       "      <td>1.352744</td>\n",
       "      <td>-0.486672</td>\n",
       "      <td>-1.106791</td>\n",
       "      <td>-0.014905</td>\n",
       "      <td>-0.742246</td>\n",
       "      <td>0.318966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.854948</td>\n",
       "      <td>-0.895040</td>\n",
       "      <td>-0.577355</td>\n",
       "      <td>-0.647228</td>\n",
       "      <td>1.701700</td>\n",
       "      <td>1.539210</td>\n",
       "      <td>1.367054</td>\n",
       "      <td>1.740341</td>\n",
       "      <td>1.636040</td>\n",
       "      <td>1.694016</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.778076</td>\n",
       "      <td>-0.928394</td>\n",
       "      <td>-0.319547</td>\n",
       "      <td>-0.412680</td>\n",
       "      <td>0.388380</td>\n",
       "      <td>0.980363</td>\n",
       "      <td>-0.796871</td>\n",
       "      <td>-0.166418</td>\n",
       "      <td>-1.076733</td>\n",
       "      <td>-0.265297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.822960</td>\n",
       "      <td>-0.542231</td>\n",
       "      <td>-0.608296</td>\n",
       "      <td>1.754146</td>\n",
       "      <td>1.784766</td>\n",
       "      <td>1.610830</td>\n",
       "      <td>1.431633</td>\n",
       "      <td>1.783958</td>\n",
       "      <td>1.649853</td>\n",
       "      <td>1.716896</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.623868</td>\n",
       "      <td>-1.209971</td>\n",
       "      <td>-0.311791</td>\n",
       "      <td>-0.557688</td>\n",
       "      <td>-0.121353</td>\n",
       "      <td>1.415610</td>\n",
       "      <td>-0.072873</td>\n",
       "      <td>-0.584790</td>\n",
       "      <td>-0.472864</td>\n",
       "      <td>-0.260567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.185489</td>\n",
       "      <td>-0.650381</td>\n",
       "      <td>1.920336</td>\n",
       "      <td>1.733858</td>\n",
       "      <td>1.769065</td>\n",
       "      <td>1.630653</td>\n",
       "      <td>1.431748</td>\n",
       "      <td>1.716913</td>\n",
       "      <td>1.575559</td>\n",
       "      <td>1.648439</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.204925</td>\n",
       "      <td>-1.441965</td>\n",
       "      <td>0.677037</td>\n",
       "      <td>-0.175322</td>\n",
       "      <td>-0.255244</td>\n",
       "      <td>0.513171</td>\n",
       "      <td>-1.169459</td>\n",
       "      <td>-0.658233</td>\n",
       "      <td>-0.090633</td>\n",
       "      <td>0.319449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99743</th>\n",
       "      <td>-0.331513</td>\n",
       "      <td>0.356134</td>\n",
       "      <td>-0.844403</td>\n",
       "      <td>-0.858645</td>\n",
       "      <td>-0.641962</td>\n",
       "      <td>-0.805758</td>\n",
       "      <td>-0.697388</td>\n",
       "      <td>-0.642756</td>\n",
       "      <td>-0.856450</td>\n",
       "      <td>-0.796840</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.286449</td>\n",
       "      <td>-0.457386</td>\n",
       "      <td>-0.313910</td>\n",
       "      <td>1.092455</td>\n",
       "      <td>-1.203601</td>\n",
       "      <td>0.934860</td>\n",
       "      <td>-0.202530</td>\n",
       "      <td>-0.613064</td>\n",
       "      <td>0.010541</td>\n",
       "      <td>0.138739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99744</th>\n",
       "      <td>-1.220233</td>\n",
       "      <td>-0.828050</td>\n",
       "      <td>-0.903588</td>\n",
       "      <td>-0.687250</td>\n",
       "      <td>-0.680983</td>\n",
       "      <td>-0.653949</td>\n",
       "      <td>-0.680398</td>\n",
       "      <td>-0.549913</td>\n",
       "      <td>-0.753115</td>\n",
       "      <td>-0.687278</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024849</td>\n",
       "      <td>-0.176945</td>\n",
       "      <td>-0.326877</td>\n",
       "      <td>0.339264</td>\n",
       "      <td>0.115136</td>\n",
       "      <td>-0.538031</td>\n",
       "      <td>1.039460</td>\n",
       "      <td>0.106102</td>\n",
       "      <td>-0.789529</td>\n",
       "      <td>0.160393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99745</th>\n",
       "      <td>-0.438986</td>\n",
       "      <td>-0.523291</td>\n",
       "      <td>-0.908066</td>\n",
       "      <td>-0.808672</td>\n",
       "      <td>-0.801250</td>\n",
       "      <td>-0.614802</td>\n",
       "      <td>-0.844231</td>\n",
       "      <td>-0.732196</td>\n",
       "      <td>-0.812538</td>\n",
       "      <td>-0.531270</td>\n",
       "      <td>...</td>\n",
       "      <td>0.102378</td>\n",
       "      <td>-0.428485</td>\n",
       "      <td>-0.163334</td>\n",
       "      <td>-0.339807</td>\n",
       "      <td>1.281501</td>\n",
       "      <td>1.089032</td>\n",
       "      <td>0.429298</td>\n",
       "      <td>0.445736</td>\n",
       "      <td>-0.984278</td>\n",
       "      <td>-0.468615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99746</th>\n",
       "      <td>-0.856478</td>\n",
       "      <td>-0.580928</td>\n",
       "      <td>-0.195463</td>\n",
       "      <td>-0.084748</td>\n",
       "      <td>-0.035737</td>\n",
       "      <td>-0.576595</td>\n",
       "      <td>-0.475360</td>\n",
       "      <td>-0.519312</td>\n",
       "      <td>-0.610353</td>\n",
       "      <td>-0.561646</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.584563</td>\n",
       "      <td>-0.117808</td>\n",
       "      <td>-0.142838</td>\n",
       "      <td>-0.283224</td>\n",
       "      <td>-0.190104</td>\n",
       "      <td>-0.195900</td>\n",
       "      <td>0.225551</td>\n",
       "      <td>-1.174491</td>\n",
       "      <td>-0.516408</td>\n",
       "      <td>0.472931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99747</th>\n",
       "      <td>-1.877472</td>\n",
       "      <td>0.710855</td>\n",
       "      <td>0.072642</td>\n",
       "      <td>-0.633977</td>\n",
       "      <td>-0.598054</td>\n",
       "      <td>-0.447791</td>\n",
       "      <td>-0.506353</td>\n",
       "      <td>-0.593066</td>\n",
       "      <td>-0.659019</td>\n",
       "      <td>-0.600411</td>\n",
       "      <td>...</td>\n",
       "      <td>0.150058</td>\n",
       "      <td>-0.102807</td>\n",
       "      <td>-0.238260</td>\n",
       "      <td>-1.239245</td>\n",
       "      <td>-0.300357</td>\n",
       "      <td>2.887519</td>\n",
       "      <td>-0.368612</td>\n",
       "      <td>0.053349</td>\n",
       "      <td>-0.292865</td>\n",
       "      <td>0.016332</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99748 rows × 548 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       zcr_mean   zcr_std     yin_0     yin_1     yin_2     yin_3     yin_4  \\\n",
       "0      0.167208 -0.526000 -0.605283 -0.644997 -0.667503 -0.714700 -0.783143   \n",
       "1      0.461319 -0.636900 -0.578792 -0.649733 -0.671045 -0.717349 -0.780945   \n",
       "2      0.854948 -0.895040 -0.577355 -0.647228  1.701700  1.539210  1.367054   \n",
       "3      0.822960 -0.542231 -0.608296  1.754146  1.784766  1.610830  1.431633   \n",
       "4      1.185489 -0.650381  1.920336  1.733858  1.769065  1.630653  1.431748   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "99743 -0.331513  0.356134 -0.844403 -0.858645 -0.641962 -0.805758 -0.697388   \n",
       "99744 -1.220233 -0.828050 -0.903588 -0.687250 -0.680983 -0.653949 -0.680398   \n",
       "99745 -0.438986 -0.523291 -0.908066 -0.808672 -0.801250 -0.614802 -0.844231   \n",
       "99746 -0.856478 -0.580928 -0.195463 -0.084748 -0.035737 -0.576595 -0.475360   \n",
       "99747 -1.877472  0.710855  0.072642 -0.633977 -0.598054 -0.447791 -0.506353   \n",
       "\n",
       "          yin_5     yin_6     yin_7  ...  cln_contrast_mean_4  \\\n",
       "0     -0.637137 -0.684710 -0.702930  ...            -1.427318   \n",
       "1     -0.636216 -0.683018 -0.700525  ...            -0.224404   \n",
       "2      1.740341  1.636040  1.694016  ...            -0.778076   \n",
       "3      1.783958  1.649853  1.716896  ...            -1.623868   \n",
       "4      1.716913  1.575559  1.648439  ...            -0.204925   \n",
       "...         ...       ...       ...  ...                  ...   \n",
       "99743 -0.642756 -0.856450 -0.796840  ...            -0.286449   \n",
       "99744 -0.549913 -0.753115 -0.687278  ...             0.024849   \n",
       "99745 -0.732196 -0.812538 -0.531270  ...             0.102378   \n",
       "99746 -0.519312 -0.610353 -0.561646  ...            -0.584563   \n",
       "99747 -0.593066 -0.659019 -0.600411  ...             0.150058   \n",
       "\n",
       "       cln_contrast_mean_5  cln_contrast_mean_6  cln_contrast_std_0  \\\n",
       "0                 0.074920            -0.115683            0.804020   \n",
       "1                -0.914364            -0.323859           -1.849531   \n",
       "2                -0.928394            -0.319547           -0.412680   \n",
       "3                -1.209971            -0.311791           -0.557688   \n",
       "4                -1.441965             0.677037           -0.175322   \n",
       "...                    ...                  ...                 ...   \n",
       "99743            -0.457386            -0.313910            1.092455   \n",
       "99744            -0.176945            -0.326877            0.339264   \n",
       "99745            -0.428485            -0.163334           -0.339807   \n",
       "99746            -0.117808            -0.142838           -0.283224   \n",
       "99747            -0.102807            -0.238260           -1.239245   \n",
       "\n",
       "       cln_contrast_std_1  cln_contrast_std_2  cln_contrast_std_3  \\\n",
       "0                1.606063           -1.114032           -0.851041   \n",
       "1                1.352744           -0.486672           -1.106791   \n",
       "2                0.388380            0.980363           -0.796871   \n",
       "3               -0.121353            1.415610           -0.072873   \n",
       "4               -0.255244            0.513171           -1.169459   \n",
       "...                   ...                 ...                 ...   \n",
       "99743           -1.203601            0.934860           -0.202530   \n",
       "99744            0.115136           -0.538031            1.039460   \n",
       "99745            1.281501            1.089032            0.429298   \n",
       "99746           -0.190104           -0.195900            0.225551   \n",
       "99747           -0.300357            2.887519           -0.368612   \n",
       "\n",
       "       cln_contrast_std_4  cln_contrast_std_5  cln_contrast_std_6  \n",
       "0               -0.778650           -0.453525            0.479612  \n",
       "1               -0.014905           -0.742246            0.318966  \n",
       "2               -0.166418           -1.076733           -0.265297  \n",
       "3               -0.584790           -0.472864           -0.260567  \n",
       "4               -0.658233           -0.090633            0.319449  \n",
       "...                   ...                 ...                 ...  \n",
       "99743           -0.613064            0.010541            0.138739  \n",
       "99744            0.106102           -0.789529            0.160393  \n",
       "99745            0.445736           -0.984278           -0.468615  \n",
       "99746           -1.174491           -0.516408            0.472931  \n",
       "99747            0.053349           -0.292865            0.016332  \n",
       "\n",
       "[99748 rows x 548 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_agree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall_class_vote</th>\n",
       "      <th>class_vote_1</th>\n",
       "      <th>class_vote_2</th>\n",
       "      <th>class_vote_3</th>\n",
       "      <th>class_vote_4</th>\n",
       "      <th>class_vote_5</th>\n",
       "      <th>class_vote_6</th>\n",
       "      <th>class_vote_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99743</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99744</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99745</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99746</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99747</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99748 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       overall_class_vote  class_vote_1  class_vote_2  class_vote_3  \\\n",
       "0                       0             0             0             0   \n",
       "1                       0             0             0             0   \n",
       "2                       0             0             0             0   \n",
       "3                       0             0             0             0   \n",
       "4                       0             0             0             0   \n",
       "...                   ...           ...           ...           ...   \n",
       "99743                   0             0             0             0   \n",
       "99744                   0             0             0             0   \n",
       "99745                   0             0             0             0   \n",
       "99746                   0             0             0             0   \n",
       "99747                   0             0             0             0   \n",
       "\n",
       "       class_vote_4  class_vote_5  class_vote_6  class_vote_7  \n",
       "0               0.0           0.0           0.0           NaN  \n",
       "1               0.0           0.0           0.0           NaN  \n",
       "2               0.0           0.0           0.0           NaN  \n",
       "3               0.0           0.0           0.0           NaN  \n",
       "4               0.0           0.0           0.0           NaN  \n",
       "...             ...           ...           ...           ...  \n",
       "99743           0.0           0.0           0.0           NaN  \n",
       "99744           0.0           0.0           0.0           NaN  \n",
       "99745           0.0           0.0           0.0           NaN  \n",
       "99746           0.0           0.0           0.0           NaN  \n",
       "99747           0.0           0.0           0.0           NaN  \n",
       "\n",
       "[99748 rows x 8 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lables_agree"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Drop correlated features</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop highly correlated features\n",
    "cor_stand = files_agree.corr()\n",
    "\n",
    "# with the following function we can select highly correlated features\n",
    "# it will remove the first feature that is correlated with anything other feature\n",
    "\n",
    "def correlation(corr_matrix, threshold):\n",
    "    col_corr = set()  # Set of all the names of correlated columns\n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i):\n",
    "            if abs(corr_matrix.iloc[i, j]) > threshold: # we are interested in absolute coeff value\n",
    "                colname = corr_matrix.columns[i]  # getting the name of column\n",
    "                col_corr.add(colname)\n",
    "    return col_corr\n",
    "\n",
    "corr_features_stand = correlation(cor_stand, 0.9)\n",
    "files_agree = files_agree.drop(corr_features_stand,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zcr_mean</th>\n",
       "      <th>zcr_std</th>\n",
       "      <th>yin_0</th>\n",
       "      <th>yin_1</th>\n",
       "      <th>yin_2</th>\n",
       "      <th>yin_3</th>\n",
       "      <th>yin_4</th>\n",
       "      <th>yin_5</th>\n",
       "      <th>yin_6</th>\n",
       "      <th>yin_7</th>\n",
       "      <th>...</th>\n",
       "      <th>cln_contrast_mean_4</th>\n",
       "      <th>cln_contrast_mean_5</th>\n",
       "      <th>cln_contrast_mean_6</th>\n",
       "      <th>cln_contrast_std_0</th>\n",
       "      <th>cln_contrast_std_1</th>\n",
       "      <th>cln_contrast_std_2</th>\n",
       "      <th>cln_contrast_std_3</th>\n",
       "      <th>cln_contrast_std_4</th>\n",
       "      <th>cln_contrast_std_5</th>\n",
       "      <th>cln_contrast_std_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.167208</td>\n",
       "      <td>-0.526000</td>\n",
       "      <td>-0.605283</td>\n",
       "      <td>-0.644997</td>\n",
       "      <td>-0.667503</td>\n",
       "      <td>-0.714700</td>\n",
       "      <td>-0.783143</td>\n",
       "      <td>-0.637137</td>\n",
       "      <td>-0.684710</td>\n",
       "      <td>-0.702930</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.427318</td>\n",
       "      <td>0.074920</td>\n",
       "      <td>-0.115683</td>\n",
       "      <td>0.804020</td>\n",
       "      <td>1.606063</td>\n",
       "      <td>-1.114032</td>\n",
       "      <td>-0.851041</td>\n",
       "      <td>-0.778650</td>\n",
       "      <td>-0.453525</td>\n",
       "      <td>0.479612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.461319</td>\n",
       "      <td>-0.636900</td>\n",
       "      <td>-0.578792</td>\n",
       "      <td>-0.649733</td>\n",
       "      <td>-0.671045</td>\n",
       "      <td>-0.717349</td>\n",
       "      <td>-0.780945</td>\n",
       "      <td>-0.636216</td>\n",
       "      <td>-0.683018</td>\n",
       "      <td>-0.700525</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.224404</td>\n",
       "      <td>-0.914364</td>\n",
       "      <td>-0.323859</td>\n",
       "      <td>-1.849531</td>\n",
       "      <td>1.352744</td>\n",
       "      <td>-0.486672</td>\n",
       "      <td>-1.106791</td>\n",
       "      <td>-0.014905</td>\n",
       "      <td>-0.742246</td>\n",
       "      <td>0.318966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.854948</td>\n",
       "      <td>-0.895040</td>\n",
       "      <td>-0.577355</td>\n",
       "      <td>-0.647228</td>\n",
       "      <td>1.701700</td>\n",
       "      <td>1.539210</td>\n",
       "      <td>1.367054</td>\n",
       "      <td>1.740341</td>\n",
       "      <td>1.636040</td>\n",
       "      <td>1.694016</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.778076</td>\n",
       "      <td>-0.928394</td>\n",
       "      <td>-0.319547</td>\n",
       "      <td>-0.412680</td>\n",
       "      <td>0.388380</td>\n",
       "      <td>0.980363</td>\n",
       "      <td>-0.796871</td>\n",
       "      <td>-0.166418</td>\n",
       "      <td>-1.076733</td>\n",
       "      <td>-0.265297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.822960</td>\n",
       "      <td>-0.542231</td>\n",
       "      <td>-0.608296</td>\n",
       "      <td>1.754146</td>\n",
       "      <td>1.784766</td>\n",
       "      <td>1.610830</td>\n",
       "      <td>1.431633</td>\n",
       "      <td>1.783958</td>\n",
       "      <td>1.649853</td>\n",
       "      <td>1.716896</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.623868</td>\n",
       "      <td>-1.209971</td>\n",
       "      <td>-0.311791</td>\n",
       "      <td>-0.557688</td>\n",
       "      <td>-0.121353</td>\n",
       "      <td>1.415610</td>\n",
       "      <td>-0.072873</td>\n",
       "      <td>-0.584790</td>\n",
       "      <td>-0.472864</td>\n",
       "      <td>-0.260567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.185489</td>\n",
       "      <td>-0.650381</td>\n",
       "      <td>1.920336</td>\n",
       "      <td>1.733858</td>\n",
       "      <td>1.769065</td>\n",
       "      <td>1.630653</td>\n",
       "      <td>1.431748</td>\n",
       "      <td>1.716913</td>\n",
       "      <td>1.575559</td>\n",
       "      <td>1.648439</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.204925</td>\n",
       "      <td>-1.441965</td>\n",
       "      <td>0.677037</td>\n",
       "      <td>-0.175322</td>\n",
       "      <td>-0.255244</td>\n",
       "      <td>0.513171</td>\n",
       "      <td>-1.169459</td>\n",
       "      <td>-0.658233</td>\n",
       "      <td>-0.090633</td>\n",
       "      <td>0.319449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99743</th>\n",
       "      <td>-0.331513</td>\n",
       "      <td>0.356134</td>\n",
       "      <td>-0.844403</td>\n",
       "      <td>-0.858645</td>\n",
       "      <td>-0.641962</td>\n",
       "      <td>-0.805758</td>\n",
       "      <td>-0.697388</td>\n",
       "      <td>-0.642756</td>\n",
       "      <td>-0.856450</td>\n",
       "      <td>-0.796840</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.286449</td>\n",
       "      <td>-0.457386</td>\n",
       "      <td>-0.313910</td>\n",
       "      <td>1.092455</td>\n",
       "      <td>-1.203601</td>\n",
       "      <td>0.934860</td>\n",
       "      <td>-0.202530</td>\n",
       "      <td>-0.613064</td>\n",
       "      <td>0.010541</td>\n",
       "      <td>0.138739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99744</th>\n",
       "      <td>-1.220233</td>\n",
       "      <td>-0.828050</td>\n",
       "      <td>-0.903588</td>\n",
       "      <td>-0.687250</td>\n",
       "      <td>-0.680983</td>\n",
       "      <td>-0.653949</td>\n",
       "      <td>-0.680398</td>\n",
       "      <td>-0.549913</td>\n",
       "      <td>-0.753115</td>\n",
       "      <td>-0.687278</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024849</td>\n",
       "      <td>-0.176945</td>\n",
       "      <td>-0.326877</td>\n",
       "      <td>0.339264</td>\n",
       "      <td>0.115136</td>\n",
       "      <td>-0.538031</td>\n",
       "      <td>1.039460</td>\n",
       "      <td>0.106102</td>\n",
       "      <td>-0.789529</td>\n",
       "      <td>0.160393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99745</th>\n",
       "      <td>-0.438986</td>\n",
       "      <td>-0.523291</td>\n",
       "      <td>-0.908066</td>\n",
       "      <td>-0.808672</td>\n",
       "      <td>-0.801250</td>\n",
       "      <td>-0.614802</td>\n",
       "      <td>-0.844231</td>\n",
       "      <td>-0.732196</td>\n",
       "      <td>-0.812538</td>\n",
       "      <td>-0.531270</td>\n",
       "      <td>...</td>\n",
       "      <td>0.102378</td>\n",
       "      <td>-0.428485</td>\n",
       "      <td>-0.163334</td>\n",
       "      <td>-0.339807</td>\n",
       "      <td>1.281501</td>\n",
       "      <td>1.089032</td>\n",
       "      <td>0.429298</td>\n",
       "      <td>0.445736</td>\n",
       "      <td>-0.984278</td>\n",
       "      <td>-0.468615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99746</th>\n",
       "      <td>-0.856478</td>\n",
       "      <td>-0.580928</td>\n",
       "      <td>-0.195463</td>\n",
       "      <td>-0.084748</td>\n",
       "      <td>-0.035737</td>\n",
       "      <td>-0.576595</td>\n",
       "      <td>-0.475360</td>\n",
       "      <td>-0.519312</td>\n",
       "      <td>-0.610353</td>\n",
       "      <td>-0.561646</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.584563</td>\n",
       "      <td>-0.117808</td>\n",
       "      <td>-0.142838</td>\n",
       "      <td>-0.283224</td>\n",
       "      <td>-0.190104</td>\n",
       "      <td>-0.195900</td>\n",
       "      <td>0.225551</td>\n",
       "      <td>-1.174491</td>\n",
       "      <td>-0.516408</td>\n",
       "      <td>0.472931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99747</th>\n",
       "      <td>-1.877472</td>\n",
       "      <td>0.710855</td>\n",
       "      <td>0.072642</td>\n",
       "      <td>-0.633977</td>\n",
       "      <td>-0.598054</td>\n",
       "      <td>-0.447791</td>\n",
       "      <td>-0.506353</td>\n",
       "      <td>-0.593066</td>\n",
       "      <td>-0.659019</td>\n",
       "      <td>-0.600411</td>\n",
       "      <td>...</td>\n",
       "      <td>0.150058</td>\n",
       "      <td>-0.102807</td>\n",
       "      <td>-0.238260</td>\n",
       "      <td>-1.239245</td>\n",
       "      <td>-0.300357</td>\n",
       "      <td>2.887519</td>\n",
       "      <td>-0.368612</td>\n",
       "      <td>0.053349</td>\n",
       "      <td>-0.292865</td>\n",
       "      <td>0.016332</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99748 rows × 305 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       zcr_mean   zcr_std     yin_0     yin_1     yin_2     yin_3     yin_4  \\\n",
       "0      0.167208 -0.526000 -0.605283 -0.644997 -0.667503 -0.714700 -0.783143   \n",
       "1      0.461319 -0.636900 -0.578792 -0.649733 -0.671045 -0.717349 -0.780945   \n",
       "2      0.854948 -0.895040 -0.577355 -0.647228  1.701700  1.539210  1.367054   \n",
       "3      0.822960 -0.542231 -0.608296  1.754146  1.784766  1.610830  1.431633   \n",
       "4      1.185489 -0.650381  1.920336  1.733858  1.769065  1.630653  1.431748   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "99743 -0.331513  0.356134 -0.844403 -0.858645 -0.641962 -0.805758 -0.697388   \n",
       "99744 -1.220233 -0.828050 -0.903588 -0.687250 -0.680983 -0.653949 -0.680398   \n",
       "99745 -0.438986 -0.523291 -0.908066 -0.808672 -0.801250 -0.614802 -0.844231   \n",
       "99746 -0.856478 -0.580928 -0.195463 -0.084748 -0.035737 -0.576595 -0.475360   \n",
       "99747 -1.877472  0.710855  0.072642 -0.633977 -0.598054 -0.447791 -0.506353   \n",
       "\n",
       "          yin_5     yin_6     yin_7  ...  cln_contrast_mean_4  \\\n",
       "0     -0.637137 -0.684710 -0.702930  ...            -1.427318   \n",
       "1     -0.636216 -0.683018 -0.700525  ...            -0.224404   \n",
       "2      1.740341  1.636040  1.694016  ...            -0.778076   \n",
       "3      1.783958  1.649853  1.716896  ...            -1.623868   \n",
       "4      1.716913  1.575559  1.648439  ...            -0.204925   \n",
       "...         ...       ...       ...  ...                  ...   \n",
       "99743 -0.642756 -0.856450 -0.796840  ...            -0.286449   \n",
       "99744 -0.549913 -0.753115 -0.687278  ...             0.024849   \n",
       "99745 -0.732196 -0.812538 -0.531270  ...             0.102378   \n",
       "99746 -0.519312 -0.610353 -0.561646  ...            -0.584563   \n",
       "99747 -0.593066 -0.659019 -0.600411  ...             0.150058   \n",
       "\n",
       "       cln_contrast_mean_5  cln_contrast_mean_6  cln_contrast_std_0  \\\n",
       "0                 0.074920            -0.115683            0.804020   \n",
       "1                -0.914364            -0.323859           -1.849531   \n",
       "2                -0.928394            -0.319547           -0.412680   \n",
       "3                -1.209971            -0.311791           -0.557688   \n",
       "4                -1.441965             0.677037           -0.175322   \n",
       "...                    ...                  ...                 ...   \n",
       "99743            -0.457386            -0.313910            1.092455   \n",
       "99744            -0.176945            -0.326877            0.339264   \n",
       "99745            -0.428485            -0.163334           -0.339807   \n",
       "99746            -0.117808            -0.142838           -0.283224   \n",
       "99747            -0.102807            -0.238260           -1.239245   \n",
       "\n",
       "       cln_contrast_std_1  cln_contrast_std_2  cln_contrast_std_3  \\\n",
       "0                1.606063           -1.114032           -0.851041   \n",
       "1                1.352744           -0.486672           -1.106791   \n",
       "2                0.388380            0.980363           -0.796871   \n",
       "3               -0.121353            1.415610           -0.072873   \n",
       "4               -0.255244            0.513171           -1.169459   \n",
       "...                   ...                 ...                 ...   \n",
       "99743           -1.203601            0.934860           -0.202530   \n",
       "99744            0.115136           -0.538031            1.039460   \n",
       "99745            1.281501            1.089032            0.429298   \n",
       "99746           -0.190104           -0.195900            0.225551   \n",
       "99747           -0.300357            2.887519           -0.368612   \n",
       "\n",
       "       cln_contrast_std_4  cln_contrast_std_5  cln_contrast_std_6  \n",
       "0               -0.778650           -0.453525            0.479612  \n",
       "1               -0.014905           -0.742246            0.318966  \n",
       "2               -0.166418           -1.076733           -0.265297  \n",
       "3               -0.584790           -0.472864           -0.260567  \n",
       "4               -0.658233           -0.090633            0.319449  \n",
       "...                   ...                 ...                 ...  \n",
       "99743           -0.613064            0.010541            0.138739  \n",
       "99744            0.106102           -0.789529            0.160393  \n",
       "99745            0.445736           -0.984278           -0.468615  \n",
       "99746           -1.174491           -0.516408            0.472931  \n",
       "99747            0.053349           -0.292865            0.016332  \n",
       "\n",
       "[99748 rows x 305 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_agree"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Select K best features</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "#twenty_cols = SelectKBest(mutual_info_classif, k=20)\n",
    "#twenty_cols.fit(files_agree, lables_agree['overall_class_vote'])\n",
    "#selected_features_20 = files_agree.columns[twenty_cols.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame(selected_features_20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'files_chosen_20 = pd.DataFrame()\\n\\nfor idx in selected_features_20:\\n    files_chosen_20[idx] = files_agree[idx]'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"files_chosen_20 = pd.DataFrame()\n",
    "\n",
    "for idx in selected_features_20:\n",
    "    files_chosen_20[idx] = files_agree[idx]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#files_chosen_20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'files_chosen_50 = pd.DataFrame()\\n\\nfor idx in selected_features_50:\\n    files_chosen_50[idx] = files_agree[idx]'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"files_chosen_50 = pd.DataFrame()\n",
    "\n",
    "for idx in selected_features_50:\n",
    "    files_chosen_50[idx] = files_agree[idx]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#files_chosen_50"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Train-Test-Split</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train_20, X_test_20, y_train_20, y_test_20 = train_test_split(files_chosen_20,lables_agree['overall_class_vote'],test_size = 0.2,stratify=lables_agree['overall_class_vote'], random_state=42)\n",
    "\n",
    "#X_train_50, X_test_50, y_train_50, y_test_50 = train_test_split(files_chosen_50,lables_agree['overall_class_vote'],test_size = 0.2,stratify=lables_agree['overall_class_vote'], random_state=42)\n",
    "\n",
    "#X_train_full, X_test_full, y_train_full, y_test_full = train_test_split(files_agree,lables_agree['overall_class_vote'],test_size = 0.2,stratify=lables_agree['overall_class_vote'], random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>SVM Classifier for 20 features</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"linear_classifier = svm.SVC(kernel='linear', random_state=42)\\n\\nlinear_classifier.fit(X_train_20, y_train_20)\\n# make prediction\\nlinear_classif_predictions = linear_classifier.predict(X_test_20)\\naccuracy_score(linear_classif_predictions, y_test_20)\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"linear_classifier = svm.SVC(kernel='linear', random_state=42)\n",
    "\n",
    "linear_classifier.fit(X_train_20, y_train_20)\n",
    "# make prediction\n",
    "linear_classif_predictions = linear_classifier.predict(X_test_20)\n",
    "accuracy_score(linear_classif_predictions, y_test_20)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"poly_classifier = svm.SVC(kernel='poly', random_state=42)\\n\\npoly_classifier.fit(X_train_20, y_train_20)\\n# make prediction\\npoly_classif_predictions = poly_classifier.predict(X_test_20)\\naccuracy_score(poly_classif_predictions, y_test_20)\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"poly_classifier = svm.SVC(kernel='poly', random_state=42)\n",
    "\n",
    "poly_classifier.fit(X_train_20, y_train_20)\n",
    "# make prediction\n",
    "poly_classif_predictions = poly_classifier.predict(X_test_20)\n",
    "accuracy_score(poly_classif_predictions, y_test_20)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"rbf_classifier = svm.SVC(kernel='rbf', random_state=42)\\n\\nrbf_classifier.fit(X_train_20, y_train_20)\\n# make prediction\\nrbf_classif_predictions = rbf_classifier.predict(X_test_20)\\naccuracy_score(rbf_classif_predictions, y_test_20)\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"rbf_classifier = svm.SVC(kernel='rbf', random_state=42)\n",
    "\n",
    "rbf_classifier.fit(X_train_20, y_train_20)\n",
    "# make prediction\n",
    "rbf_classif_predictions = rbf_classifier.predict(X_test_20)\n",
    "accuracy_score(rbf_classif_predictions, y_test_20)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"linear_classifier_f1 = f1_score(y_test_20, linear_classif_predictions, average='macro')\\npoly_classifier_f1 = f1_score(y_test_20, poly_classif_predictions, average='macro')\\nrbf_classifier_f1 = f1_score(y_test_20, rbf_classif_predictions, average='macro')\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"linear_classifier_f1 = f1_score(y_test_20, linear_classif_predictions, average='macro')\n",
    "poly_classifier_f1 = f1_score(y_test_20, poly_classif_predictions, average='macro')\n",
    "rbf_classifier_f1 = f1_score(y_test_20, rbf_classif_predictions, average='macro')\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'print(linear_classifier_f1)\\nprint(poly_classifier_f1)\\nprint(rbf_classifier_f1)'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"print(linear_classifier_f1)\n",
    "print(poly_classifier_f1)\n",
    "print(rbf_classifier_f1)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"linear_classifier_f1 = f1_score(y_test_20, linear_classif_predictions, average='weighted')\\npoly_classifier_f1 = f1_score(y_test_20, poly_classif_predictions, average='weighted')\\nrbf_classifier_f1 = f1_score(y_test_20, rbf_classif_predictions, average='weighted')\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"linear_classifier_f1 = f1_score(y_test_20, linear_classif_predictions, average='weighted')\n",
    "poly_classifier_f1 = f1_score(y_test_20, poly_classif_predictions, average='weighted')\n",
    "rbf_classifier_f1 = f1_score(y_test_20, rbf_classif_predictions, average='weighted')\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'print(linear_classifier_f1)\\nprint(poly_classifier_f1)\\nprint(rbf_classifier_f1)'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"print(linear_classifier_f1)\n",
    "print(poly_classifier_f1)\n",
    "print(rbf_classifier_f1)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"linear_classifier_f1 = f1_score(y_test_20, linear_classif_predictions, average='micro')\\npoly_classifier_f1 = f1_score(y_test_20, poly_classif_predictions, average='micro')\\nrbf_classifier_f1 = f1_score(y_test_20, rbf_classif_predictions, average='micro')\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"linear_classifier_f1 = f1_score(y_test_20, linear_classif_predictions, average='micro')\n",
    "poly_classifier_f1 = f1_score(y_test_20, poly_classif_predictions, average='micro')\n",
    "rbf_classifier_f1 = f1_score(y_test_20, rbf_classif_predictions, average='micro')\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'print(linear_classifier_f1)\\nprint(poly_classifier_f1)\\nprint(rbf_classifier_f1)'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"print(linear_classifier_f1)\n",
    "print(poly_classifier_f1)\n",
    "print(rbf_classifier_f1)\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>50 features</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "fifty_cols = SelectKBest(mutual_info_classif, k=50)\n",
    "fifty_cols.fit(files_agree, lables_agree['overall_class_vote'])\n",
    "selected_features_50 = files_agree.columns[fifty_cols.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_chosen_50 = pd.DataFrame()\n",
    "\n",
    "for idx in selected_features_50:\n",
    "    files_chosen_50[idx] = files_agree[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zcr_mean</th>\n",
       "      <th>raw_melspect_mean_4</th>\n",
       "      <th>raw_melspect_mean_5</th>\n",
       "      <th>raw_melspect_mean_6</th>\n",
       "      <th>raw_melspect_mean_7</th>\n",
       "      <th>raw_melspect_mean_8</th>\n",
       "      <th>raw_melspect_mean_9</th>\n",
       "      <th>raw_melspect_mean_10</th>\n",
       "      <th>raw_melspect_mean_11</th>\n",
       "      <th>raw_melspect_mean_12</th>\n",
       "      <th>...</th>\n",
       "      <th>raw_contrast_mean_3</th>\n",
       "      <th>cln_flatness_mean</th>\n",
       "      <th>cln_centroid_mean</th>\n",
       "      <th>cln_centroid_std</th>\n",
       "      <th>cln_flux_mean</th>\n",
       "      <th>cln_flux_std</th>\n",
       "      <th>cln_energy_std</th>\n",
       "      <th>cln_bandwidth_mean</th>\n",
       "      <th>cln_contrast_mean_3</th>\n",
       "      <th>cln_contrast_mean_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.167208</td>\n",
       "      <td>0.413676</td>\n",
       "      <td>0.351911</td>\n",
       "      <td>0.182678</td>\n",
       "      <td>-0.001713</td>\n",
       "      <td>-0.367584</td>\n",
       "      <td>-0.493130</td>\n",
       "      <td>-0.811764</td>\n",
       "      <td>-0.494151</td>\n",
       "      <td>-0.535799</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.193519</td>\n",
       "      <td>0.623446</td>\n",
       "      <td>0.948781</td>\n",
       "      <td>-0.596810</td>\n",
       "      <td>-0.447192</td>\n",
       "      <td>-0.487065</td>\n",
       "      <td>-0.443302</td>\n",
       "      <td>-0.147406</td>\n",
       "      <td>-1.066098</td>\n",
       "      <td>-1.427318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.461319</td>\n",
       "      <td>-0.855740</td>\n",
       "      <td>0.033231</td>\n",
       "      <td>-0.059496</td>\n",
       "      <td>-0.188944</td>\n",
       "      <td>-0.213440</td>\n",
       "      <td>0.041397</td>\n",
       "      <td>0.137262</td>\n",
       "      <td>0.020711</td>\n",
       "      <td>-0.150333</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.444102</td>\n",
       "      <td>0.947370</td>\n",
       "      <td>0.847815</td>\n",
       "      <td>-0.609965</td>\n",
       "      <td>-0.548157</td>\n",
       "      <td>-0.530030</td>\n",
       "      <td>-0.363591</td>\n",
       "      <td>-0.271310</td>\n",
       "      <td>-1.044733</td>\n",
       "      <td>-0.224404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.854948</td>\n",
       "      <td>0.191515</td>\n",
       "      <td>-0.750290</td>\n",
       "      <td>-0.783740</td>\n",
       "      <td>-0.732563</td>\n",
       "      <td>-0.692779</td>\n",
       "      <td>-0.414533</td>\n",
       "      <td>-1.120994</td>\n",
       "      <td>-0.896223</td>\n",
       "      <td>-0.951161</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.664926</td>\n",
       "      <td>0.872882</td>\n",
       "      <td>1.227718</td>\n",
       "      <td>-0.055447</td>\n",
       "      <td>-0.612837</td>\n",
       "      <td>-0.637614</td>\n",
       "      <td>-0.269222</td>\n",
       "      <td>0.188035</td>\n",
       "      <td>-0.305408</td>\n",
       "      <td>-0.778076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.822960</td>\n",
       "      <td>-0.165756</td>\n",
       "      <td>0.174313</td>\n",
       "      <td>-0.412357</td>\n",
       "      <td>-0.677561</td>\n",
       "      <td>-0.748280</td>\n",
       "      <td>-0.769436</td>\n",
       "      <td>-1.669452</td>\n",
       "      <td>-2.492285</td>\n",
       "      <td>-0.867254</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.219770</td>\n",
       "      <td>1.150775</td>\n",
       "      <td>1.022415</td>\n",
       "      <td>-0.495100</td>\n",
       "      <td>-0.791180</td>\n",
       "      <td>-0.688336</td>\n",
       "      <td>-0.372902</td>\n",
       "      <td>0.320006</td>\n",
       "      <td>-0.382392</td>\n",
       "      <td>-1.623868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.185489</td>\n",
       "      <td>0.244198</td>\n",
       "      <td>-0.320617</td>\n",
       "      <td>-0.825520</td>\n",
       "      <td>-0.931514</td>\n",
       "      <td>-0.686089</td>\n",
       "      <td>-1.062352</td>\n",
       "      <td>-1.561100</td>\n",
       "      <td>-0.029832</td>\n",
       "      <td>0.035515</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.886440</td>\n",
       "      <td>0.438736</td>\n",
       "      <td>0.705754</td>\n",
       "      <td>-0.851837</td>\n",
       "      <td>-0.672211</td>\n",
       "      <td>-0.523607</td>\n",
       "      <td>-0.303215</td>\n",
       "      <td>0.116443</td>\n",
       "      <td>-0.754747</td>\n",
       "      <td>-0.204925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99743</th>\n",
       "      <td>-0.331513</td>\n",
       "      <td>0.688131</td>\n",
       "      <td>0.232498</td>\n",
       "      <td>-0.014584</td>\n",
       "      <td>0.781043</td>\n",
       "      <td>0.300814</td>\n",
       "      <td>0.781700</td>\n",
       "      <td>0.192967</td>\n",
       "      <td>-0.249391</td>\n",
       "      <td>-0.527454</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.038263</td>\n",
       "      <td>0.313846</td>\n",
       "      <td>0.071795</td>\n",
       "      <td>-0.097555</td>\n",
       "      <td>-0.234323</td>\n",
       "      <td>-0.194769</td>\n",
       "      <td>-0.096655</td>\n",
       "      <td>0.412820</td>\n",
       "      <td>-0.184484</td>\n",
       "      <td>-0.286449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99744</th>\n",
       "      <td>-1.220233</td>\n",
       "      <td>1.402616</td>\n",
       "      <td>0.555731</td>\n",
       "      <td>-0.039212</td>\n",
       "      <td>0.328129</td>\n",
       "      <td>0.012447</td>\n",
       "      <td>0.277539</td>\n",
       "      <td>0.595299</td>\n",
       "      <td>0.264265</td>\n",
       "      <td>0.057460</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.348975</td>\n",
       "      <td>0.149666</td>\n",
       "      <td>0.010778</td>\n",
       "      <td>-0.007063</td>\n",
       "      <td>-0.287017</td>\n",
       "      <td>-0.225641</td>\n",
       "      <td>-0.185162</td>\n",
       "      <td>1.113627</td>\n",
       "      <td>0.169436</td>\n",
       "      <td>0.024849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99745</th>\n",
       "      <td>-0.438986</td>\n",
       "      <td>0.461479</td>\n",
       "      <td>0.801244</td>\n",
       "      <td>0.357578</td>\n",
       "      <td>-0.329339</td>\n",
       "      <td>-0.725959</td>\n",
       "      <td>-0.480579</td>\n",
       "      <td>-0.321559</td>\n",
       "      <td>-0.241697</td>\n",
       "      <td>0.001902</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.236202</td>\n",
       "      <td>0.280166</td>\n",
       "      <td>-0.123845</td>\n",
       "      <td>-0.243513</td>\n",
       "      <td>-0.284446</td>\n",
       "      <td>-0.230821</td>\n",
       "      <td>-0.306870</td>\n",
       "      <td>0.845862</td>\n",
       "      <td>-0.368649</td>\n",
       "      <td>0.102378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99746</th>\n",
       "      <td>-0.856478</td>\n",
       "      <td>-0.305130</td>\n",
       "      <td>-0.579203</td>\n",
       "      <td>-0.303088</td>\n",
       "      <td>-0.088837</td>\n",
       "      <td>0.512104</td>\n",
       "      <td>0.852607</td>\n",
       "      <td>0.421025</td>\n",
       "      <td>-0.099590</td>\n",
       "      <td>-0.649966</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.322785</td>\n",
       "      <td>0.151287</td>\n",
       "      <td>-0.175674</td>\n",
       "      <td>-0.153192</td>\n",
       "      <td>-0.281631</td>\n",
       "      <td>-0.204688</td>\n",
       "      <td>-0.181617</td>\n",
       "      <td>0.901573</td>\n",
       "      <td>-0.186372</td>\n",
       "      <td>-0.584563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99747</th>\n",
       "      <td>-1.877472</td>\n",
       "      <td>-0.648010</td>\n",
       "      <td>-0.913679</td>\n",
       "      <td>-0.455656</td>\n",
       "      <td>-0.385853</td>\n",
       "      <td>-1.060739</td>\n",
       "      <td>-0.263063</td>\n",
       "      <td>0.772858</td>\n",
       "      <td>-0.275831</td>\n",
       "      <td>-0.527648</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.544753</td>\n",
       "      <td>0.120592</td>\n",
       "      <td>-0.068313</td>\n",
       "      <td>0.617738</td>\n",
       "      <td>-0.294600</td>\n",
       "      <td>-0.163597</td>\n",
       "      <td>0.595331</td>\n",
       "      <td>1.139793</td>\n",
       "      <td>-0.275394</td>\n",
       "      <td>0.150058</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99748 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       zcr_mean  raw_melspect_mean_4  raw_melspect_mean_5  \\\n",
       "0      0.167208             0.413676             0.351911   \n",
       "1      0.461319            -0.855740             0.033231   \n",
       "2      0.854948             0.191515            -0.750290   \n",
       "3      0.822960            -0.165756             0.174313   \n",
       "4      1.185489             0.244198            -0.320617   \n",
       "...         ...                  ...                  ...   \n",
       "99743 -0.331513             0.688131             0.232498   \n",
       "99744 -1.220233             1.402616             0.555731   \n",
       "99745 -0.438986             0.461479             0.801244   \n",
       "99746 -0.856478            -0.305130            -0.579203   \n",
       "99747 -1.877472            -0.648010            -0.913679   \n",
       "\n",
       "       raw_melspect_mean_6  raw_melspect_mean_7  raw_melspect_mean_8  \\\n",
       "0                 0.182678            -0.001713            -0.367584   \n",
       "1                -0.059496            -0.188944            -0.213440   \n",
       "2                -0.783740            -0.732563            -0.692779   \n",
       "3                -0.412357            -0.677561            -0.748280   \n",
       "4                -0.825520            -0.931514            -0.686089   \n",
       "...                    ...                  ...                  ...   \n",
       "99743            -0.014584             0.781043             0.300814   \n",
       "99744            -0.039212             0.328129             0.012447   \n",
       "99745             0.357578            -0.329339            -0.725959   \n",
       "99746            -0.303088            -0.088837             0.512104   \n",
       "99747            -0.455656            -0.385853            -1.060739   \n",
       "\n",
       "       raw_melspect_mean_9  raw_melspect_mean_10  raw_melspect_mean_11  \\\n",
       "0                -0.493130             -0.811764             -0.494151   \n",
       "1                 0.041397              0.137262              0.020711   \n",
       "2                -0.414533             -1.120994             -0.896223   \n",
       "3                -0.769436             -1.669452             -2.492285   \n",
       "4                -1.062352             -1.561100             -0.029832   \n",
       "...                    ...                   ...                   ...   \n",
       "99743             0.781700              0.192967             -0.249391   \n",
       "99744             0.277539              0.595299              0.264265   \n",
       "99745            -0.480579             -0.321559             -0.241697   \n",
       "99746             0.852607              0.421025             -0.099590   \n",
       "99747            -0.263063              0.772858             -0.275831   \n",
       "\n",
       "       raw_melspect_mean_12  ...  raw_contrast_mean_3  cln_flatness_mean  \\\n",
       "0                 -0.535799  ...            -0.193519           0.623446   \n",
       "1                 -0.150333  ...            -0.444102           0.947370   \n",
       "2                 -0.951161  ...            -0.664926           0.872882   \n",
       "3                 -0.867254  ...            -0.219770           1.150775   \n",
       "4                  0.035515  ...            -0.886440           0.438736   \n",
       "...                     ...  ...                  ...                ...   \n",
       "99743             -0.527454  ...            -0.038263           0.313846   \n",
       "99744              0.057460  ...            -0.348975           0.149666   \n",
       "99745              0.001902  ...            -0.236202           0.280166   \n",
       "99746             -0.649966  ...            -0.322785           0.151287   \n",
       "99747             -0.527648  ...            -0.544753           0.120592   \n",
       "\n",
       "       cln_centroid_mean  cln_centroid_std  cln_flux_mean  cln_flux_std  \\\n",
       "0               0.948781         -0.596810      -0.447192     -0.487065   \n",
       "1               0.847815         -0.609965      -0.548157     -0.530030   \n",
       "2               1.227718         -0.055447      -0.612837     -0.637614   \n",
       "3               1.022415         -0.495100      -0.791180     -0.688336   \n",
       "4               0.705754         -0.851837      -0.672211     -0.523607   \n",
       "...                  ...               ...            ...           ...   \n",
       "99743           0.071795         -0.097555      -0.234323     -0.194769   \n",
       "99744           0.010778         -0.007063      -0.287017     -0.225641   \n",
       "99745          -0.123845         -0.243513      -0.284446     -0.230821   \n",
       "99746          -0.175674         -0.153192      -0.281631     -0.204688   \n",
       "99747          -0.068313          0.617738      -0.294600     -0.163597   \n",
       "\n",
       "       cln_energy_std  cln_bandwidth_mean  cln_contrast_mean_3  \\\n",
       "0           -0.443302           -0.147406            -1.066098   \n",
       "1           -0.363591           -0.271310            -1.044733   \n",
       "2           -0.269222            0.188035            -0.305408   \n",
       "3           -0.372902            0.320006            -0.382392   \n",
       "4           -0.303215            0.116443            -0.754747   \n",
       "...               ...                 ...                  ...   \n",
       "99743       -0.096655            0.412820            -0.184484   \n",
       "99744       -0.185162            1.113627             0.169436   \n",
       "99745       -0.306870            0.845862            -0.368649   \n",
       "99746       -0.181617            0.901573            -0.186372   \n",
       "99747        0.595331            1.139793            -0.275394   \n",
       "\n",
       "       cln_contrast_mean_4  \n",
       "0                -1.427318  \n",
       "1                -0.224404  \n",
       "2                -0.778076  \n",
       "3                -1.623868  \n",
       "4                -0.204925  \n",
       "...                    ...  \n",
       "99743            -0.286449  \n",
       "99744             0.024849  \n",
       "99745             0.102378  \n",
       "99746            -0.584563  \n",
       "99747             0.150058  \n",
       "\n",
       "[99748 rows x 50 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_chosen_50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs('trainset_python/reduced_dataset')\n",
    "files_chosen_50.to_csv('trainset_python/reduced_dataset/files_chosen_50.cvs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "lables_agree.to_csv('trainset_python/reduced_dataset/labels_50.cvs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_50, X_test_50, y_train_50, y_test_50 = train_test_split(files_chosen_50,lables_agree['overall_class_vote'],test_size = 0.2,stratify=lables_agree['overall_class_vote'], random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"linear_classifier_f50 = svm.SVC(kernel='linear', random_state=42)\\n\\nlinear_classifier_f50.fit(X_train_50, y_train_50)\\n# make prediction\\nlinear_classif_predictions_f50 = linear_classifier_f50.predict(X_test_50)\\naccuracy_score(linear_classif_predictions_f50, y_test_50)\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"linear_classifier_f50 = svm.SVC(kernel='linear', random_state=42)\n",
    "\n",
    "linear_classifier_f50.fit(X_train_50, y_train_50)\n",
    "# make prediction\n",
    "linear_classif_predictions_f50 = linear_classifier_f50.predict(X_test_50)\n",
    "accuracy_score(linear_classif_predictions_f50, y_test_50)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"poly_classifier_f50 = svm.SVC(kernel='poly', random_state=42)\\n\\npoly_classifier_f50.fit(X_train_50, y_train_50)\\n# make prediction\\npoly_classif_predictions_f50 = poly_classifier_f50.predict(X_test_50)\\naccuracy_score(poly_classif_predictions_f50, y_test_50)\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"poly_classifier_f50 = svm.SVC(kernel='poly', random_state=42)\n",
    "\n",
    "poly_classifier_f50.fit(X_train_50, y_train_50)\n",
    "# make prediction\n",
    "poly_classif_predictions_f50 = poly_classifier_f50.predict(X_test_50)\n",
    "accuracy_score(poly_classif_predictions_f50, y_test_50)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"rbf_classifier_f50 = svm.SVC(kernel='rbf', random_state=42)\\n\\nrbf_classifier_f50.fit(X_train_50, y_train_50)\\n# make prediction\\nrbf_classif_predictions_f50 = rbf_classifier_f50.predict(X_test_50)\\naccuracy_score(rbf_classif_predictions_f50, y_test_50)\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"rbf_classifier_f50 = svm.SVC(kernel='rbf', random_state=42)\n",
    "\n",
    "rbf_classifier_f50.fit(X_train_50, y_train_50)\n",
    "# make prediction\n",
    "rbf_classif_predictions_f50 = rbf_classifier_f50.predict(X_test_50)\n",
    "accuracy_score(rbf_classif_predictions_f50, y_test_50)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"linear_classifier_f1_f50 = f1_score(y_test_50, linear_classif_predictions_f50, average='macro')\\npoly_classifier_f1_f50 = f1_score(y_test_50, poly_classif_predictions_f50, average='macro')\\nrbf_classifier_f1_f50 = f1_score(y_test_50, rbf_classif_predictions_f50, average='macro')\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"linear_classifier_f1_f50 = f1_score(y_test_50, linear_classif_predictions_f50, average='macro')\n",
    "poly_classifier_f1_f50 = f1_score(y_test_50, poly_classif_predictions_f50, average='macro')\n",
    "rbf_classifier_f1_f50 = f1_score(y_test_50, rbf_classif_predictions_f50, average='macro')\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'print(linear_classifier_f1_f50)\\nprint(poly_classifier_f1_f50)\\nprint(rbf_classifier_f1_f50)'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"print(linear_classifier_f1_f50)\n",
    "print(poly_classifier_f1_f50)\n",
    "print(rbf_classifier_f1_f50)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_dict = {\n",
    "    'kernel': ['rbf'],\n",
    "    'gamma': ['auto'],\n",
    "    'degree': [3, 5, 7, 9, 11, 13, 15, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30],\n",
    "    'tol': [1e-3]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"for kernel in svm_dict['kernel']:\\n    for gamma in svm_dict['gamma']:\\n        for tol in svm_dict['tol']:\\n            for degree in svm_dict['degree']:\\n                classifier = svm.SVC(kernel=kernel, gamma=gamma, degree=degree, tol=1e-3, random_state=42, cache_size=1024)\\n                classifier.fit(X_train_50, y_train_50)\\n                # make prediction\\n                pred = classifier.predict(X_test_50)\\n                accuracy_score(rbf_classif_predictions, y_test_20)\\n                print(f'Classifier with kernel={kernel}, degree={degree}, gamma={gamma}, tol={tol} -> accuracy = {acc_cv}')\\n                print(f'Classifier with kernel={kernel}, degree={degree}, gamma={gamma}, tol={tol} -> accuracy = {acc_train}')\\n                print()\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate,  StratifiedKFold\n",
    "from sklearn.metrics import average_precision_score, make_scorer\n",
    "\n",
    "ap = make_scorer(average_precision_score)\n",
    "\n",
    "cross_validation = StratifiedKFold(n_splits=5)\n",
    "accs_train = []\n",
    "accs_cv = []\n",
    "\n",
    "\"\"\"for kernel in svm_dict['kernel']:\n",
    "    for gamma in svm_dict['gamma']:\n",
    "        for tol in svm_dict['tol']:\n",
    "            for degree in svm_dict['degree']:\n",
    "                classifier = svm.SVC(kernel=kernel, gamma=gamma, degree=degree, tol=1e-3, random_state=42, cache_size=1024)\n",
    "                classifier.fit(X_train_50, y_train_50)\n",
    "                # make prediction\n",
    "                pred = classifier.predict(X_test_50)\n",
    "                accuracy_score(rbf_classif_predictions, y_test_20)\n",
    "                print(f'Classifier with kernel={kernel}, degree={degree}, gamma={gamma}, tol={tol} -> accuracy = {acc_cv}')\n",
    "                print(f'Classifier with kernel={kernel}, degree={degree}, gamma={gamma}, tol={tol} -> accuracy = {acc_train}')\n",
    "                print()\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accs_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accs_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2160x432 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "list_accs_cv_f20 = [0.4292043364914601, 0.429157236168379, 0.4297407755508459, 0.4292043364914601, 0.429157236168379, 0.4297407755508459, 0.5594302028437397, 0.5594302028437397, 0.5595133267895878,\n",
    "                    0.5566779218702129, 0.5566570338774909, 0.5567433727382229, 0.6294297078832145, 0.6294927970623252, 0.6296740765511395, 0.6288166902986829, 0.6288237104320895, 0.6287918307277847]\n",
    "list_accs_train_f20 = [0.4336433955325102, 0.4337055617155565, 0.43372363558328564, 0.4336433955325102, 0.4337055617155565, 0.43372363558328564, 0.6219952004339078, 0.6220160240762307, 0.6220351042289407,\n",
    "                       0.617767146828768, 0.6177678186768427, 0.617848177606281, 0.684827702444599, 0.6848429456198822, 0.6848484469478047, 0.6822685195541487, 0.6822465763661392, 0.682242541342983]\n",
    "\n",
    "\n",
    "list_accs_cv_f50 = [0.5887976606153424, 0.5887690550834879, 0.58848177267039, 0.5887976606153424, 0.5887690550834879, 0.58848177267039, 0.7118474913418011, 0.7118542502832009, 0.7119224330345231,\n",
    "                    0.7111884629922562, 0.7111151097795588, 0.7111131516458598, 0.77338137836, 0.7733814008803476, 0.7733814008803476, 0.77339178738273, 0.77339863836183, 0.773472792793]\n",
    "list_accs_train_f50 = [0.5955183602874777, 0.5955025395505328, 0.5955761079843741, 0.5955183602874777, 0.5955025395505328, 0.5955761079843741, 0.8119084621128307, 0.8119020498665588, 0.8119595043995707,\n",
    "                     0.8095956298094693, 0.8095876231366379, 0.8096238639725767, 0.84469378743, 0.8447270748107005, 0.84473353355, 0.84474464566, 0.8447634734, 0.84443456385]\n",
    "\n",
    "\n",
    "fig, axis = plt.subplots(nrows=1, ncols=3, figsize=(30, 6))\n",
    "\n",
    "n = 6\n",
    "tol = [1e-4, 1e-3, 1e-2]\n",
    "\n",
    "axis[0].set_ylabel('Macro F1-Score')\n",
    "axis[1].set_ylabel('Macro F1-Score')\n",
    "axis[2].set_ylabel('Macro F1-Score')\n",
    "\n",
    "axis[0].set_xlabel('Gamma')\n",
    "axis[1].set_xlabel('Gamma')\n",
    "axis[2].set_xlabel('Gamma')\n",
    "\n",
    "# axis 0\n",
    "axis[0].plot(['auto1', 'scale1'], list_accs_train_f20[:2], color='red', label='training')\n",
    "axis[0].plot(['auto2', 'scale2'], list_accs_train_f20[2:4], color='red')\n",
    "axis[0].plot(['auto3', 'scale3'], list_accs_train_f20[4:6], color='red')\n",
    "\n",
    "axis[0].plot(['auto1', 'scale1'], list_accs_cv_f20[:2], color='green', label='test')\n",
    "axis[0].plot(['auto2', 'scale2'], list_accs_cv_f20[2:4], color='green')\n",
    "axis[0].plot(['auto3', 'scale3'], list_accs_cv_f20[4:6], color='green')\n",
    "\n",
    "axis[0].axvline(1.5, c='black', linestyle=':')\n",
    "axis[0].axvline(3.5, c='black', linestyle=':')\n",
    "axis[0].text(0, (max(list_accs_cv_f20[:2]) + max(list_accs_train_f20[:2]))/2, f'Tol={tol[0]}')\n",
    "axis[0].text(2, (max(list_accs_cv_f20[2:4]) + max(list_accs_train_f20[2:4]))/2, f'Tol={tol[1]}')\n",
    "axis[0].text(4, (max(list_accs_cv_f20[4:6]) + max(list_accs_train_f20[4:6]))/2, f'Tol={tol[2]}')\n",
    "\n",
    "\n",
    "# axis 1\n",
    "axis[1].plot(['auto1', 'scale1'], list_accs_train_f20[6:8], color='red', label='training')\n",
    "axis[1].plot(['auto2', 'scale2'], list_accs_train_f20[8:10], color='red')\n",
    "axis[1].plot(['auto3', 'scale3'], list_accs_train_f20[10:12], color='red')\n",
    "\n",
    "axis[1].plot(['auto1', 'scale1'], list_accs_cv_f20[6:8], color='green', label='test')\n",
    "axis[1].plot(['auto2', 'scale2'], list_accs_cv_f20[8:10], color='green')\n",
    "axis[1].plot(['auto3', 'scale3'], list_accs_cv_f20[10:12], color='green')\n",
    "\n",
    "axis[1].axvline(1.5, c='black', linestyle=':')\n",
    "axis[1].axvline(3.5, c='black', linestyle=':')\n",
    "axis[1].text(0, (max(list_accs_cv_f20[6:8]) + max(list_accs_train_f20[6:8]))/2, f'Tol={tol[0]}')\n",
    "axis[1].text(2, (max(list_accs_cv_f20[8:10]) + max(list_accs_train_f20[8:10]))/2, f'Tol={tol[1]}')\n",
    "axis[1].text(4, (max(list_accs_cv_f20[10:12]) + max(list_accs_train_f20[10:12]))/2, f'Tol={tol[2]}')\n",
    "\n",
    "\n",
    "\n",
    "# axis 2\n",
    "axis[2].plot(['auto1', 'scale1'], list_accs_train_f20[12:14], color='red', label='training')\n",
    "axis[2].plot(['auto2', 'scale2'], list_accs_train_f20[14:16], color='red')\n",
    "axis[2].plot(['auto3', 'scale3'], list_accs_train_f20[16:18], color='red')\n",
    "\n",
    "axis[2].plot(['auto1', 'scale1'], list_accs_cv_f20[12:14], color='green', label='test')\n",
    "axis[2].plot(['auto2', 'scale2'], list_accs_cv_f20[14:16], color='green')\n",
    "axis[2].plot(['auto3', 'scale3'], list_accs_cv_f20[16:18], color='green')\n",
    "\n",
    "axis[2].axvline(1.5, c='black', linestyle=':')\n",
    "axis[2].axvline(3.5, c='black', linestyle=':')\n",
    "axis[2].text(0, (max(list_accs_cv_f20[12:14]) + max(list_accs_train_f20[12:14]))/2, f'Tol={tol[0]}')\n",
    "axis[2].text(2, (max(list_accs_cv_f20[14:16]) + max(list_accs_train_f20[14:16]))/2, f'Tol={tol[1]}')\n",
    "axis[2].text(4, (max(list_accs_cv_f20[16:18]) + max(list_accs_train_f20[16:18]))/2, f'Tol={tol[2]}')\n",
    "\n",
    "axis[0].legend()\n",
    "axis[1].legend()\n",
    "axis[2].legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve, precision_recall_fscore_support, average_precision_score\n",
    "from sklearn.metrics import recall_score, f1_score, precision_score, PrecisionRecallDisplay\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from itertools import cycle\n",
    "from scipy import interp\n",
    "\n",
    "def prec_rec(classifier, X_test, y_test):\n",
    "    predictions = classifier.predict(X_test)\n",
    "    y_score = classifier.predict_proba(X_test)\n",
    "    classes=[0, 1, 2, 3, 4, 5, 6]\n",
    "    \n",
    "    y_test_bin = label_binarize(y_test, classes=classes)\n",
    "    # For each class\n",
    "    precision = dict()\n",
    "    recall = dict()\n",
    "    average_precision = dict()\n",
    "    for i in range(7):\n",
    "        precision[i], recall[i], _ = precision_recall_curve(y_test_bin[:, i], y_score[:, i])\n",
    "        average_precision[i] = average_precision_score(y_test_bin[:, i], y_score[:, i])\n",
    "    '''\n",
    "    # A \"micro-average\": quantifying score on all classes jointly\n",
    "    precision[\"micro\"], recall[\"micro\"], _ = precision_recall_curve(\n",
    "        y_test_bin.ravel(), y_score.ravel()\n",
    "    )\n",
    "    '''\n",
    "    \n",
    "    all_precision = np.unique(np.concatenate([precision[i] for i in range(len(classes))]))\n",
    "    \n",
    "    # Then interpolate all ROC curves at this points\n",
    "    mean_recall = np.zeros_like(all_precision)\n",
    "    for i in range(len(classes)):\n",
    "        mean_recall += np.interp(all_precision, precision[i], recall[i])\n",
    "\n",
    "    # Finally average it and compute AUC\n",
    "    mean_recall /= len(classes)\n",
    "\n",
    "    precision[\"macro\"] = all_precision\n",
    "    recall[\"macro\"] = mean_recall\n",
    "    average_precision[\"macro\"] = average_precision_score(y_test_bin, y_score, average=\"macro\")   \n",
    "    \n",
    "    '''\n",
    "    display = PrecisionRecallDisplay(\n",
    "        recall=recall[\"macro\"],\n",
    "        precision=precision[\"macro\"],\n",
    "        average_precision=average_precision[\"macro\"],\n",
    "    )  \n",
    "    \n",
    "    display.plot()\n",
    "    _ = display.ax_.set_title(\"Macro-averaged over all classes\")\n",
    "    '''\n",
    "    \n",
    "    colors = cycle([\"navy\", \"turquoise\", \"darkorange\", \"cornflowerblue\", \"teal\", 'r', 'g'])\n",
    "\n",
    "    _, ax = plt.subplots(figsize=(7, 8))\n",
    "\n",
    "    f_scores = np.linspace(0.2, 0.8, num=4)\n",
    "    lines, labels = [], []\n",
    "\n",
    "    display_1 = PrecisionRecallDisplay(\n",
    "        recall=recall[\"macro\"],\n",
    "        precision=precision[\"macro\"],\n",
    "        average_precision=average_precision[\"macro\"],\n",
    "    )\n",
    "    display_1.plot(ax=ax, name=\"Macro-average precision-recall\", color=\"gold\")\n",
    "\n",
    "    for i, color in zip(range(7), colors):\n",
    "        display = PrecisionRecallDisplay(\n",
    "            recall=recall[i],\n",
    "            precision=precision[i],\n",
    "            average_precision=average_precision[i],\n",
    "        )\n",
    "        display.plot(ax=ax, name=f\"Precision-recall for class {i}\", color=color)\n",
    "    \n",
    "    handles, labels = display_1.ax_.get_legend_handles_labels()\n",
    "\n",
    "    # set the legend and the axes\n",
    "    ax.set_xlim([0.0, 1.0])\n",
    "    ax.set_ylim([0.0, 1.05])\n",
    "    ax.legend(handles=handles, labels=labels, loc=\"best\")\n",
    "    ax.set_title(\"Extension of Precision-Recall curve to multi-class\")\n",
    "\n",
    "    plt.show()\n",
    "    print(average_precision[\"macro\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8831578947368421"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_classifier = svm.SVC(kernel='rbf', random_state=42, cache_size=1024, probability=True)\n",
    "\n",
    "best_classifier.fit(X_train_50,y_train_50)\n",
    "# make prediction \n",
    "preds = best_classifier.predict(X_test_50) \n",
    "# check performance\n",
    "accuracy_score(preds,y_test_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prec_rec' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\Dokumente\\Studium\\OneDrive_JKU\\OneDrive - Johannes Kepler Universität Linz\\SS2023\\ML_Pattern_Classification\\EX\\SS23_UE_MLPC\\svm.ipynb Cell 52\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Dokumente/Studium/OneDrive_JKU/OneDrive%20-%20Johannes%20Kepler%20Universit%C3%A4t%20Linz/SS2023/ML_Pattern_Classification/EX/SS23_UE_MLPC/svm.ipynb#Y102sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m prec_rec(best_classifier, X_test_50, y_test_50)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'prec_rec' is not defined"
     ]
    }
   ],
   "source": [
    "prec_rec(best_classifier, X_test_50, y_test_50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ho2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
